"""
CueNote Core - AI ì±—ë´‡ ë¼ìš°í„°
ì‚¬ìš©ì ìì—°ì–´ ëª…ë ¹ì„ ë¶„ì„í•˜ì—¬ ì•± ê¸°ëŠ¥(ë„êµ¬)ì„ ìë™ ì‹¤í–‰í•˜ëŠ” ëŒ€í™”í˜• ì¸í„°í˜ì´ìŠ¤
"""
import json
import re
import shutil
from datetime import datetime, date
from typing import Optional
from pathlib import Path

from fastapi import APIRouter, HTTPException
from pydantic import BaseModel, Field
from sse_starlette.sse import EventSourceResponse

from ..config import logger
from .. import ollama_client, gemini_client, openai_client, anthropic_client

try:
    from duckduckgo_search import DDGS
    HAS_DDGS = True
except ImportError:
    HAS_DDGS = False
    logger.warning("duckduckgo-search not installed, web_search tool disabled")

router = APIRouter(prefix="/chatbot", tags=["chatbot"])


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ìŠ¤í‚¤ë§ˆ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class ChatMessage(BaseModel):
    role: str = Field(..., description="ë©”ì‹œì§€ ì—­í•  (user, assistant, tool_call, tool_result)")
    content: str = Field(..., description="ë©”ì‹œì§€ ë‚´ìš©")

class ChatPayload(BaseModel):
    message: str = Field(..., description="ì‚¬ìš©ì ë©”ì‹œì§€")
    provider: str = Field(default="ollama", description="LLM ì œê³µì")
    api_key: str = Field(default="", description="API í‚¤")
    model: str = Field(default="", description="ëª¨ë¸ëª…")
    history: list[ChatMessage] = Field(default_factory=list, description="ëŒ€í™” íˆìŠ¤í† ë¦¬")
    active_note_path: str = Field(default="", description="í˜„ì¬ ì—´ë ¤ìˆëŠ” ë…¸íŠ¸ ê²½ë¡œ")
    active_note_content: str = Field(default="", description="í˜„ì¬ ì—´ë ¤ìˆëŠ” ë…¸íŠ¸ ë‚´ìš©")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# CueNote ë‚´ì¥ ë„êµ¬ ì •ì˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

CUENOTE_TOOLS = [
    {
        "name": "create_note",
        "description": "ìƒˆ ë…¸íŠ¸(ë§ˆí¬ë‹¤ìš´ íŒŒì¼)ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ì œëª©ì„ ì§€ì •í•˜ë©´ í•´ë‹¹ ì´ë¦„ìœ¼ë¡œ íŒŒì¼ì´ ìƒì„±ë©ë‹ˆë‹¤.",
        "parameters": {
            "title": {"type": "string", "description": "ë…¸íŠ¸ ì œëª© (íŒŒì¼ëª…, .md ì œì™¸)", "required": False},
            "content": {"type": "string", "description": "ë…¸íŠ¸ ì´ˆê¸° ë‚´ìš© (ë§ˆí¬ë‹¤ìš´)", "required": False},
            "folder": {"type": "string", "description": "í´ë” ê²½ë¡œ (ì˜ˆ: 'projects/ideas')", "required": False}
        }
    },
    {
        "name": "list_notes",
        "description": "í˜„ì¬ ë³¼íŠ¸ì˜ ëª¨ë“  ë…¸íŠ¸ íŒŒì¼ ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤.",
        "parameters": {}
    },
    {
        "name": "read_note",
        "description": "íŠ¹ì • ë…¸íŠ¸ì˜ ë‚´ìš©ì„ ì½ì–´ì˜µë‹ˆë‹¤.",
        "parameters": {
            "path": {"type": "string", "description": "ë…¸íŠ¸ íŒŒì¼ ê²½ë¡œ (ì˜ˆ: 'meeting-notes.md')", "required": True}
        }
    },
    {
        "name": "save_note",
        "description": "ë…¸íŠ¸ì˜ ë‚´ìš©ì„ ì €ì¥í•©ë‹ˆë‹¤.",
        "parameters": {
            "path": {"type": "string", "description": "ë…¸íŠ¸ íŒŒì¼ ê²½ë¡œ", "required": True},
            "content": {"type": "string", "description": "ì €ì¥í•  ë‚´ìš©", "required": True}
        }
    },
    {
        "name": "delete_note",
        "description": "ë…¸íŠ¸ë¥¼ íœ´ì§€í†µìœ¼ë¡œ ì´ë™í•©ë‹ˆë‹¤.",
        "parameters": {
            "path": {"type": "string", "description": "ì‚­ì œí•  ë…¸íŠ¸ ê²½ë¡œ", "required": True}
        }
    },
    {
        "name": "search_notes",
        "description": "ë…¸íŠ¸ ì œëª©ì´ë‚˜ ë‚´ìš©ì—ì„œ í‚¤ì›Œë“œë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.",
        "parameters": {
            "query": {"type": "string", "description": "ê²€ìƒ‰ í‚¤ì›Œë“œ", "required": True}
        }
    },
    {
        "name": "create_schedule",
        "description": "ìƒˆ ì¼ì •ì„ ìƒì„±í•©ë‹ˆë‹¤.",
        "parameters": {
            "title": {"type": "string", "description": "ì¼ì • ì œëª©", "required": True},
            "date": {"type": "string", "description": "ì¼ì • ë‚ ì§œ (YYYY-MM-DD)", "required": True},
            "startTime": {"type": "string", "description": "ì‹œì‘ ì‹œê°„ (HH:MM)", "required": False},
            "endTime": {"type": "string", "description": "ì¢…ë£Œ ì‹œê°„ (HH:MM)", "required": False},
            "description": {"type": "string", "description": "ì¼ì • ì„¤ëª…", "required": False}
        }
    },
    {
        "name": "list_schedules",
        "description": "ì¼ì • ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤. íŠ¹ì • ë‚ ì§œë‚˜ ì›”ë³„ë¡œ í•„í„°ë§ ê°€ëŠ¥í•©ë‹ˆë‹¤.",
        "parameters": {
            "date": {"type": "string", "description": "íŠ¹ì • ë‚ ì§œ (YYYY-MM-DD)", "required": False},
            "month": {"type": "string", "description": "ì›”ë³„ ì¡°íšŒ (YYYY-MM)", "required": False}
        }
    },
    {
        "name": "delete_schedule",
        "description": "ì¼ì •ì„ ì‚­ì œí•©ë‹ˆë‹¤.",
        "parameters": {
            "schedule_id": {"type": "string", "description": "ì‚­ì œí•  ì¼ì • ID", "required": True}
        }
    },
    {
        "name": "list_todos",
        "description": "ëª¨ë“  ë…¸íŠ¸ì—ì„œ TODO í•­ëª©(ì²´í¬ë¦¬ìŠ¤íŠ¸)ì„ ì¡°íšŒí•©ë‹ˆë‹¤.",
        "parameters": {}
    },
    {
        "name": "summarize_text",
        "description": "ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ë¥¼ ìš”ì•½í•©ë‹ˆë‹¤.",
        "parameters": {
            "content": {"type": "string", "description": "ìš”ì•½í•  í…ìŠ¤íŠ¸", "required": True}
        }
    },
    {
        "name": "translate_text",
        "description": "í…ìŠ¤íŠ¸ë¥¼ ë‹¤ë¥¸ ì–¸ì–´ë¡œ ë²ˆì—­í•©ë‹ˆë‹¤.",
        "parameters": {
            "content": {"type": "string", "description": "ë²ˆì—­í•  í…ìŠ¤íŠ¸", "required": True},
            "target_language": {"type": "string", "description": "ëŒ€ìƒ ì–¸ì–´ ì½”ë“œ (ko, en, ja, zh ë“±)", "required": True}
        }
    },
    {
        "name": "create_folder",
        "description": "ìƒˆ í´ë”ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.",
        "parameters": {
            "path": {"type": "string", "description": "í´ë” ê²½ë¡œ (ì˜ˆ: 'projects/new-project')", "required": True}
        }
    },
    {
        "name": "web_search",
        "description": "ì›¹ì—ì„œ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤. ìµœì‹  ë‰´ìŠ¤, ê¸°ì‚¬, ì •ë³´ ë“±ì„ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
        "parameters": {
            "query": {"type": "string", "description": "ê²€ìƒ‰í•  í‚¤ì›Œë“œ ë˜ëŠ” ë¬¸ì¥", "required": True},
            "max_results": {"type": "integer", "description": "ìµœëŒ€ ê²°ê³¼ ìˆ˜ (ê¸°ë³¸: 5)", "required": False}
        }
    },
    {
        "name": "smart_search_notes",
        "description": "ë…¸íŠ¸ ë‚´ìš©ì„ AIë¡œ ë¶„ì„í•˜ì—¬ íŠ¹ì • ì •ë³´ê°€ í¬í•¨ëœ ë…¸íŠ¸ë¥¼ ì°¾ìŠµë‹ˆë‹¤. ë‹¨ìˆœ í‚¤ì›Œë“œê°€ ì•„ë‹Œ ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰ì…ë‹ˆë‹¤.",
        "parameters": {
            "query": {"type": "string", "description": "ì°¾ê³  ì‹¶ì€ ì •ë³´ (ìì—°ì–´ë¡œ ì„¤ëª…)", "required": True}
        }
    },
    {
        "name": "organize_notes",
        "description": "ëª¨ë“  ë…¸íŠ¸ë¥¼ AIê°€ ë¶„ì„í•˜ì—¬ ì£¼ì œë³„ í´ë”ë¡œ ìë™ ì •ë¦¬í•©ë‹ˆë‹¤.",
        "parameters": {}
    },
    {
        "name": "move_note",
        "description": "ë…¸íŠ¸ë¥¼ ë‹¤ë¥¸ í´ë”ë¡œ ì´ë™í•©ë‹ˆë‹¤.",
        "parameters": {
            "path": {"type": "string", "description": "ì´ë™í•  ë…¸íŠ¸ ê²½ë¡œ", "required": True},
            "destination": {"type": "string", "description": "ëŒ€ìƒ í´ë” ê²½ë¡œ", "required": True}
        }
    },
]


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë„êµ¬ ì‹¤í–‰ í•¨ìˆ˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

async def execute_tool(tool_name: str, args: dict, provider: str = "", api_key: str = "", model: str = "") -> dict:
    """CueNote ë‚´ì¥ ë„êµ¬ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤."""
    try:
        if tool_name == "create_note":
            return await _create_note(args)
        elif tool_name == "list_notes":
            return await _list_notes()
        elif tool_name == "read_note":
            return await _read_note(args)
        elif tool_name == "save_note":
            return await _save_note(args)
        elif tool_name == "delete_note":
            return await _delete_note(args)
        elif tool_name == "search_notes":
            return await _search_notes(args)
        elif tool_name == "create_schedule":
            return await _create_schedule(args)
        elif tool_name == "list_schedules":
            return await _list_schedules(args)
        elif tool_name == "delete_schedule":
            return await _delete_schedule(args)
        elif tool_name == "list_todos":
            return await _list_todos()
        elif tool_name == "summarize_text":
            return await _summarize_text(args)
        elif tool_name == "translate_text":
            return await _translate_text(args)
        elif tool_name == "create_folder":
            return await _create_folder(args)
        elif tool_name == "web_search":
            return await _web_search(args)
        elif tool_name == "smart_search_notes":
            return await _smart_search_notes(args, provider, api_key, model)
        elif tool_name == "organize_notes":
            return await _organize_notes(args, provider, api_key, model)
        elif tool_name == "move_note":
            return await _move_note(args)
        else:
            return {"error": f"Unknown tool: {tool_name}"}
    except Exception as e:
        logger.error(f"Tool execution failed [{tool_name}]: {e}")
        return {"error": str(e)}


async def _create_note(args: dict) -> dict:
    """ë…¸íŠ¸ ìƒì„±"""
    from .vault import get_current_vault_path
    
    vault_path = get_current_vault_path()
    title = args.get("title", "")
    content = args.get("content", "")
    folder = args.get("folder", "")
    
    if not title:
        # ìë™ ìƒì„±: í˜„ì¬ ì‹œê°„ ê¸°ë°˜
        title = f"ìƒˆ ë…¸íŠ¸ {datetime.now().strftime('%Y%m%d_%H%M%S')}"
    
    # íŒŒì¼ ê²½ë¡œ ìƒì„±
    filename = f"{title}.md"
    if folder:
        file_path = vault_path / folder / filename
        file_path.parent.mkdir(parents=True, exist_ok=True)
    else:
        file_path = vault_path / filename
    
    if file_path.exists():
        return {"error": f"'{title}.md' íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤."}
    
    # ê¸°ë³¸ ë‚´ìš© ìƒì„±
    if not content:
        content = f"# {title}\n\n"
    
    file_path.write_text(content, encoding="utf-8")
    rel_path = str(file_path.relative_to(vault_path)).replace("\\", "/")
    
    return {
        "success": True,
        "path": rel_path,
        "message": f"ë…¸íŠ¸ '{title}' ìƒì„± ì™„ë£Œ"
    }


async def _list_notes() -> dict:
    """ë…¸íŠ¸ ëª©ë¡ ì¡°íšŒ"""
    from .vault import get_current_vault_path
    
    vault_path = get_current_vault_path()
    notes = []
    
    for md_file in sorted(vault_path.rglob("*.md")):
        rel_path = str(md_file.relative_to(vault_path)).replace("\\", "/")
        if rel_path.startswith(".trash/") or "/.trash/" in rel_path:
            continue
        
        stat = md_file.stat()
        notes.append({
            "path": rel_path,
            "title": rel_path.replace(".md", ""),
            "size": stat.st_size,
            "modified": datetime.fromtimestamp(stat.st_mtime).strftime("%Y-%m-%d %H:%M")
        })
    
    return {
        "notes": notes,
        "count": len(notes),
        "message": f"ì´ {len(notes)}ê°œì˜ ë…¸íŠ¸"
    }


async def _read_note(args: dict) -> dict:
    """ë…¸íŠ¸ ì½ê¸°"""
    from .vault import get_current_vault_path
    
    vault_path = get_current_vault_path()
    path = args.get("path", "")
    if not path:
        return {"error": "ë…¸íŠ¸ ê²½ë¡œê°€ í•„ìš”í•©ë‹ˆë‹¤."}
    
    file_path = vault_path / path
    if not file_path.exists():
        return {"error": f"'{path}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
    
    content = file_path.read_text(encoding="utf-8")
    return {
        "path": path,
        "content": content[:5000],  # ì±—ë´‡ìš©ìœ¼ë¡œ ì•ë¶€ë¶„ë§Œ
        "full_length": len(content),
        "truncated": len(content) > 5000
    }


async def _save_note(args: dict) -> dict:
    """ë…¸íŠ¸ ì €ì¥"""
    from .vault import get_current_vault_path
    
    vault_path = get_current_vault_path()
    path = args.get("path", "")
    content = args.get("content", "")
    
    if not path:
        return {"error": "ë…¸íŠ¸ ê²½ë¡œê°€ í•„ìš”í•©ë‹ˆë‹¤."}
    
    file_path = vault_path / path
    file_path.parent.mkdir(parents=True, exist_ok=True)
    file_path.write_text(content, encoding="utf-8")
    
    return {
        "success": True,
        "path": path,
        "message": f"'{path}' ì €ì¥ ì™„ë£Œ"
    }


async def _delete_note(args: dict) -> dict:
    """ë…¸íŠ¸ ì‚­ì œ (íœ´ì§€í†µìœ¼ë¡œ)"""
    from .vault import get_current_vault_path, get_trash_path
    import shutil
    
    vault_path = get_current_vault_path()
    trash_path = get_trash_path()
    path = args.get("path", "")
    
    if not path:
        return {"error": "ì‚­ì œí•  ë…¸íŠ¸ ê²½ë¡œê°€ í•„ìš”í•©ë‹ˆë‹¤."}
    
    file_path = vault_path / path
    if not file_path.exists():
        return {"error": f"'{path}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
    
    trash_path.mkdir(parents=True, exist_ok=True)
    dest = trash_path / file_path.name
    shutil.move(str(file_path), str(dest))
    
    return {
        "success": True,
        "path": path,
        "message": f"'{path}' íŒŒì¼ì´ íœ´ì§€í†µìœ¼ë¡œ ì´ë™ë¨"
    }


async def _search_notes(args: dict) -> dict:
    """ë…¸íŠ¸ ê²€ìƒ‰"""
    from .vault import get_current_vault_path
    
    vault_path = get_current_vault_path()
    query = args.get("query", "").lower()
    if not query:
        return {"error": "ê²€ìƒ‰ì–´ê°€ í•„ìš”í•©ë‹ˆë‹¤."}
    
    results = []
    for md_file in vault_path.rglob("*.md"):
        rel_path = str(md_file.relative_to(vault_path)).replace("\\", "/")
        if rel_path.startswith(".trash/") or "/.trash/" in rel_path:
            continue
        
        title = rel_path.replace(".md", "")
        title_match = query in title.lower()
        
        content_match = False
        snippet = ""
        try:
            content = md_file.read_text(encoding="utf-8")
            idx = content.lower().find(query)
            if idx >= 0:
                content_match = True
                start = max(0, idx - 50)
                end = min(len(content), idx + len(query) + 50)
                snippet = "..." + content[start:end] + "..."
        except Exception:
            pass
        
        if title_match or content_match:
            results.append({
                "path": rel_path,
                "title": title,
                "match": "title" if title_match else "content",
                "snippet": snippet if content_match else ""
            })
    
    return {
        "results": results[:20],
        "count": len(results),
        "query": query,
        "message": f"'{query}' ê²€ìƒ‰ ê²°ê³¼: {len(results)}ê±´"
    }


async def _create_schedule(args: dict) -> dict:
    """ì¼ì • ìƒì„±"""
    import uuid
    from ..db import get_conn
    
    title = args.get("title", "")
    schedule_date = args.get("date", "")
    
    if not title:
        return {"error": "ì¼ì • ì œëª©ì´ í•„ìš”í•©ë‹ˆë‹¤."}
    if not schedule_date:
        schedule_date = date.today().isoformat()
    
    schedule_id = str(uuid.uuid4())
    now = datetime.now().isoformat()
    
    start_time = args.get("startTime", "")
    end_time = args.get("endTime", "")
    description = args.get("description", "")
    
    conn = get_conn()
    try:
        conn.execute(
            """INSERT INTO schedules (id, title, description, date, start_time, end_time, color, completed, created_at, updated_at)
               VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)""",
            (schedule_id, title, description, schedule_date, start_time, end_time, "#c9a76c", 0, now, now)
        )
        conn.commit()
    finally:
        conn.close()
    
    return {
        "success": True,
        "schedule_id": schedule_id,
        "title": title,
        "date": schedule_date,
        "startTime": start_time,
        "endTime": end_time,
        "message": f"ì¼ì • '{title}' ({schedule_date}) ìƒì„± ì™„ë£Œ"
    }


async def _list_schedules(args: dict) -> dict:
    """ì¼ì • ëª©ë¡ ì¡°íšŒ"""
    from ..db import get_conn
    
    schedule_date = args.get("date", "")
    month = args.get("month", "")
    
    conn = get_conn()
    try:
        if schedule_date:
            rows = conn.execute(
                "SELECT * FROM schedules WHERE date = ? ORDER BY start_time", (schedule_date,)
            ).fetchall()
        elif month:
            rows = conn.execute(
                "SELECT * FROM schedules WHERE date LIKE ? ORDER BY date, start_time", (f"{month}%",)
            ).fetchall()
        else:
            today = date.today().isoformat()
            rows = conn.execute(
                "SELECT * FROM schedules WHERE date >= ? ORDER BY date, start_time LIMIT 50", (today,)
            ).fetchall()
    finally:
        conn.close()
    
    schedules = []
    for row in rows:
        schedules.append({
            "id": row[0],
            "title": row[1],
            "description": row[2],
            "date": row[3],
            "startTime": row[4],
            "endTime": row[5],
            "color": row[6],
            "completed": bool(row[7])
        })
    
    return {
        "schedules": schedules,
        "count": len(schedules),
        "message": f"{len(schedules)}ê±´ì˜ ì¼ì •"
    }


async def _delete_schedule(args: dict) -> dict:
    """ì¼ì • ì‚­ì œ"""
    from ..db import get_conn
    
    schedule_id = args.get("schedule_id", "")
    if not schedule_id:
        return {"error": "ì‚­ì œí•  ì¼ì • IDê°€ í•„ìš”í•©ë‹ˆë‹¤."}
    
    conn = get_conn()
    try:
        cursor = conn.execute("DELETE FROM schedules WHERE id = ?", (schedule_id,))
        conn.commit()
    finally:
        conn.close()
    
    if cursor.rowcount == 0:
        return {"error": f"ì¼ì • '{schedule_id}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
    
    return {
        "success": True,
        "schedule_id": schedule_id,
        "message": "ì¼ì • ì‚­ì œ ì™„ë£Œ"
    }


async def _list_todos() -> dict:
    """TODO ëª©ë¡ ì¡°íšŒ"""
    from .vault import get_current_vault_path
    
    vault_path = get_current_vault_path()
    todo_pattern = re.compile(r"^\s*-\s*\[(?P<checked>[ xX])\]\s+(?P<text>.+)\s*$")
    
    todos = []
    for md_file in vault_path.rglob("*.md"):
        rel_path = str(md_file.relative_to(vault_path)).replace("\\", "/")
        if rel_path.startswith(".trash/") or "/.trash/" in rel_path:
            continue
        
        try:
            content = md_file.read_text(encoding="utf-8")
            for i, line in enumerate(content.split("\n"), 1):
                m = todo_pattern.match(line)
                if m:
                    todos.append({
                        "text": m.group("text").strip(),
                        "checked": m.group("checked").strip().lower() == "x",
                        "notePath": rel_path,
                        "lineNo": i
                    })
        except Exception:
            pass
    
    unchecked = [t for t in todos if not t["checked"]]
    checked = [t for t in todos if t["checked"]]
    
    return {
        "todos": todos[:50],
        "total": len(todos),
        "unchecked": len(unchecked),
        "checked": len(checked),
        "message": f"TODO {len(todos)}ê°œ (ë¯¸ì™„ë£Œ: {len(unchecked)}, ì™„ë£Œ: {len(checked)})"
    }


async def _summarize_text(args: dict) -> dict:
    """í…ìŠ¤íŠ¸ ìš”ì•½ (ë™ê¸° í˜¸ì¶œ)"""
    content = args.get("content", "")
    if not content:
        return {"error": "ìš”ì•½í•  í…ìŠ¤íŠ¸ê°€ í•„ìš”í•©ë‹ˆë‹¤."}
    
    return {
        "content": content[:3000],
        "action": "summarize",
        "message": "í…ìŠ¤íŠ¸ë¥¼ ìš”ì•½í•©ë‹ˆë‹¤."
    }


async def _translate_text(args: dict) -> dict:
    """í…ìŠ¤íŠ¸ ë²ˆì—­ (ë™ê¸° í˜¸ì¶œ)"""
    content = args.get("content", "")
    target = args.get("target_language", "en")
    if not content:
        return {"error": "ë²ˆì—­í•  í…ìŠ¤íŠ¸ê°€ í•„ìš”í•©ë‹ˆë‹¤."}
    
    return {
        "content": content[:3000],
        "target_language": target,
        "action": "translate",
        "message": f"í…ìŠ¤íŠ¸ë¥¼ {target}ë¡œ ë²ˆì—­í•©ë‹ˆë‹¤."
    }


async def _create_folder(args: dict) -> dict:
    """í´ë” ìƒì„±"""
    from .vault import get_current_vault_path
    
    vault_path = get_current_vault_path()
    path = args.get("path", "")
    if not path:
        return {"error": "í´ë” ê²½ë¡œê°€ í•„ìš”í•©ë‹ˆë‹¤."}
    
    folder_path = vault_path / path
    if folder_path.exists():
        return {"error": f"'{path}' í´ë”ê°€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤."}
    
    folder_path.mkdir(parents=True, exist_ok=True)
    
    return {
        "success": True,
        "path": path,
        "message": f"í´ë” '{path}' ìƒì„± ì™„ë£Œ"
    }


async def _web_search(args: dict) -> dict:
    """ì›¹ ê²€ìƒ‰ (DuckDuckGo)"""
    if not HAS_DDGS:
        return {"error": "ì›¹ ê²€ìƒ‰ ê¸°ëŠ¥ì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. (pip install duckduckgo-search)"}
    
    query = args.get("query", "")
    max_results = args.get("max_results", 5)
    if not query:
        return {"error": "ê²€ìƒ‰ì–´ê°€ í•„ìš”í•©ë‹ˆë‹¤."}
    
    try:
        with DDGS() as ddgs:
            results = list(ddgs.text(query, max_results=max_results))
        
        formatted = []
        for r in results:
            formatted.append({
                "title": r.get("title", ""),
                "url": r.get("href", ""),
                "snippet": r.get("body", "")
            })
        
        # ê²€ìƒ‰ ê²°ê³¼ë¥¼ í…ìŠ¤íŠ¸ë¡œë„ ì •ë¦¬
        text_summary = f"'{query}' ê²€ìƒ‰ ê²°ê³¼:\n\n"
        for i, r in enumerate(formatted, 1):
            text_summary += f"{i}. **{r['title']}**\n   {r['snippet']}\n   ğŸ”— {r['url']}\n\n"
        
        return {
            "results": formatted,
            "count": len(formatted),
            "query": query,
            "text_summary": text_summary,
            "message": f"'{query}' ê²€ìƒ‰ ê²°ê³¼: {len(formatted)}ê±´"
        }
    except Exception as e:
        logger.error(f"Web search failed: {e}")
        return {"error": f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"}


async def _smart_search_notes(args: dict, provider: str = "", api_key: str = "", model: str = "") -> dict:
    """AI ê¸°ë°˜ ìŠ¤ë§ˆíŠ¸ ë…¸íŠ¸ ê²€ìƒ‰"""
    from .vault import get_current_vault_path
    
    vault_path = get_current_vault_path()
    query = args.get("query", "")
    if not query:
        return {"error": "ê²€ìƒ‰í•  ì •ë³´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”."}
    
    # ëª¨ë“  ë…¸íŠ¸ ìˆ˜ì§‘ (ì œëª© + ë‚´ìš© ì•ë¶€ë¶„)
    notes_info = []
    for md_file in sorted(vault_path.rglob("*.md")):
        rel_path = str(md_file.relative_to(vault_path)).replace("\\", "/")
        if rel_path.startswith(".trash/") or "/.trash/" in rel_path:
            continue
        try:
            content = md_file.read_text(encoding="utf-8")[:1000]
            notes_info.append({
                "path": rel_path,
                "title": rel_path.replace(".md", ""),
                "preview": content
            })
        except Exception:
            pass
    
    if not notes_info:
        return {"results": [], "count": 0, "message": "ë…¸íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤."}
    
    # LLMìœ¼ë¡œ ê´€ë ¨ ë…¸íŠ¸ ì°¾ê¸°
    notes_text = ""
    for i, n in enumerate(notes_info[:30]):  # ìµœëŒ€ 30ê°œ
        notes_text += f"\n[{i}] ê²½ë¡œ: {n['path']}\në‚´ìš© ë¯¸ë¦¬ë³´ê¸°: {n['preview'][:300]}\n---\n"
    
    search_prompt = f"""ë‹¤ìŒ ë…¸íŠ¸ ëª©ë¡ì—ì„œ \"{query}\" ì •ë³´ê°€ í¬í•¨ëœ ë…¸íŠ¸ë¥¼ ì°¾ì•„ì£¼ì„¸ìš”.

{notes_text}

ê´€ë ¨ëœ ë…¸íŠ¸ì˜ ì¸ë±ìŠ¤ ë²ˆí˜¸ë¥¼ JSON ë°°ì—´ë¡œ ì‘ë‹µí•˜ì„¸ìš”. ì˜ˆ: [0, 3, 5]
ê´€ë ¨ ë…¸íŠ¸ê°€ ì—†ìœ¼ë©´ ë¹ˆ ë°°ì—´ []ì„ ì‘ë‹µí•˜ì„¸ìš”.
ì¸ë±ìŠ¤ ë²ˆí˜¸ë§Œ í¬í•¨ëœ JSON ë°°ì—´ë§Œ ì¶œë ¥í•˜ì„¸ìš”."""
    
    try:
        llm_result = call_llm_text(search_prompt, provider, api_key, model)
        # JSON ë°°ì—´ íŒŒì‹±
        match = re.search(r'\[([\d,\s]*)\]', llm_result)
        if match:
            indices = json.loads(f"[{match.group(1)}]")
            matched = []
            for idx in indices:
                if 0 <= idx < len(notes_info):
                    matched.append(notes_info[idx])
            return {
                "results": matched,
                "count": len(matched),
                "query": query,
                "message": f"'{query}' ê´€ë ¨ ë…¸íŠ¸: {len(matched)}ê±´"
            }
        else:
            return {"results": [], "count": 0, "query": query, "message": "ê´€ë ¨ ë…¸íŠ¸ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."}
    except Exception as e:
        logger.error(f"Smart search failed: {e}")
        return {"error": f"ìŠ¤ë§ˆíŠ¸ ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}"}


async def _organize_notes(args: dict, provider: str = "", api_key: str = "", model: str = "") -> dict:
    """AI ê¸°ë°˜ ë…¸íŠ¸ ìë™ ì •ë¦¬"""
    from .vault import get_current_vault_path
    
    vault_path = get_current_vault_path()
    
    # ë£¨íŠ¸ ë ˆë²¨ ë…¸íŠ¸ë§Œ ìˆ˜ì§‘ (ì´ë¯¸ í´ë”ì— ìˆëŠ” ê±´ ì œì™¸)
    root_notes = []
    for md_file in sorted(vault_path.glob("*.md")):
        rel_path = md_file.name
        try:
            content = md_file.read_text(encoding="utf-8")[:500]
            root_notes.append({
                "path": rel_path,
                "title": rel_path.replace(".md", ""),
                "preview": content
            })
        except Exception:
            pass
    
    if not root_notes:
        return {"message": "ì •ë¦¬í•  ë£¨íŠ¸ ë ˆë²¨ ë…¸íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.", "moved": []}
    
    # LLMìœ¼ë¡œ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
    notes_text = ""
    for i, n in enumerate(root_notes):
        notes_text += f"[{i}] {n['title']}: {n['preview'][:200]}\n"
    
    organize_prompt = f"""ë‹¤ìŒ ë…¸íŠ¸ë“¤ì„ ì£¼ì œë³„ í´ë”ë¡œ ë¶„ë¥˜í•´ì£¼ì„¸ìš”.

{notes_text}

ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:
{{
  "categories": [
    {{
      "folder": "í´ë”ëª… (ì˜ë¬¸ kebab-case, ì˜ˆ: project-ideas)",
      "label": "í´ë” í•œêµ­ì–´ ì´ë¦„",
      "notes": [0, 2, 5]
    }}
  ]
}}

ê·œì¹™:
- í´ë”ëª…ì€ ì˜ë¬¸ kebab-case
- ë¶„ë¥˜í•˜ê¸° ì• ë§¤í•œ ë…¸íŠ¸ëŠ” "misc" í´ë”ì—
- JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”"""
    
    try:
        llm_result = call_llm_text(organize_prompt, provider, api_key, model)
        
        # JSON íŒŒì‹±
        json_match = re.search(r'\{.*"categories".*\}', llm_result, re.DOTALL)
        if not json_match:
            return {"error": "ë¶„ë¥˜ ê²°ê³¼ë¥¼ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", "raw": llm_result[:300]}
        
        parsed = json.loads(json_match.group(0))
        categories = parsed.get("categories", [])
        
        moved = []
        for cat in categories:
            folder = cat.get("folder", "misc")
            label = cat.get("label", folder)
            note_indices = cat.get("notes", [])
            
            folder_path = vault_path / folder
            folder_path.mkdir(parents=True, exist_ok=True)
            
            for idx in note_indices:
                if 0 <= idx < len(root_notes):
                    note = root_notes[idx]
                    src = vault_path / note["path"]
                    dst = folder_path / note["path"]
                    if src.exists() and not dst.exists():
                        shutil.move(str(src), str(dst))
                        moved.append({"note": note["title"], "folder": folder, "label": label})
        
        return {
            "success": True,
            "moved": moved,
            "count": len(moved),
            "message": f"{len(moved)}ê°œ ë…¸íŠ¸ë¥¼ í´ë”ë³„ë¡œ ì •ë¦¬í–ˆìŠµë‹ˆë‹¤."
        }
    except json.JSONDecodeError:
        return {"error": "LLM ë¶„ë¥˜ ê²°ê³¼ íŒŒì‹± ì‹¤íŒ¨"}
    except Exception as e:
        logger.error(f"Organize notes failed: {e}")
        return {"error": f"ì •ë¦¬ ì˜¤ë¥˜: {str(e)}"}


async def _move_note(args: dict) -> dict:
    """ë…¸íŠ¸ ì´ë™"""
    from .vault import get_current_vault_path
    
    vault_path = get_current_vault_path()
    path = args.get("path", "")
    destination = args.get("destination", "")
    
    if not path:
        return {"error": "ì´ë™í•  ë…¸íŠ¸ ê²½ë¡œê°€ í•„ìš”í•©ë‹ˆë‹¤."}
    if not destination:
        return {"error": "ëŒ€ìƒ í´ë” ê²½ë¡œê°€ í•„ìš”í•©ë‹ˆë‹¤."}
    
    src = vault_path / path
    if not src.exists():
        return {"error": f"'{path}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
    
    dest_folder = vault_path / destination
    dest_folder.mkdir(parents=True, exist_ok=True)
    dst = dest_folder / src.name
    
    if dst.exists():
        return {"error": f"ëŒ€ìƒ ìœ„ì¹˜ì— '{src.name}' íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤."}
    
    shutil.move(str(src), str(dst))
    new_path = str(dst.relative_to(vault_path)).replace("\\", "/")
    
    return {
        "success": True,
        "original_path": path,
        "new_path": new_path,
        "message": f"'{path}' â†’ '{new_path}' ì´ë™ ì™„ë£Œ"
    }


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# í”„ë¡¬í”„íŠ¸ ìƒì„±
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def build_tool_descriptions() -> str:
    """ë„êµ¬ ì„¤ëª…ì„ ë¬¸ìì—´ë¡œ ë³€í™˜"""
    lines = []
    for tool in CUENOTE_TOOLS:
        params = tool.get("parameters", {})
        param_desc = ""
        if params:
            param_parts = []
            for pname, pinfo in params.items():
                req = " (í•„ìˆ˜)" if pinfo.get("required") else " (ì„ íƒ)"
                param_parts.append(f"    - {pname}: {pinfo['description']}{req}")
            param_desc = "\n" + "\n".join(param_parts)
        lines.append(f"  - {tool['name']}: {tool['description']}{param_desc}")
    return "\n".join(lines)


def build_chat_prompt(
    user_message: str,
    history: list[ChatMessage],
    today: str,
    active_note_path: str = "",
    active_note_content: str = "",
) -> str:
    """ì±—ë´‡ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
    tools_desc = build_tool_descriptions()
    
    # ëŒ€í™” íˆìŠ¤í† ë¦¬ í¬ë§· (ë” ëª…í™•í•˜ê²Œ)
    history_block = ""
    last_assistant_content = ""
    if history:
        hist_lines = []
        for msg in history[-10:]:
            if msg.role == "user":
                hist_lines.append(f"[ì‚¬ìš©ì]: {msg.content}")
            elif msg.role == "assistant":
                content = msg.content
                if len(content) > 2000:
                    content = content[:2000] + "\n... (ì´í•˜ ìƒëµ)"
                hist_lines.append(f"[ì–´ì‹œìŠ¤í„´íŠ¸]: {content}")
                last_assistant_content = msg.content
        history_block = "\n\n".join(hist_lines)
    
    # ë§ˆì§€ë§‰ ì–´ì‹œìŠ¤í„´íŠ¸ ì‘ë‹µì´ ìˆìœ¼ë©´ ëª…ì‹œì ìœ¼ë¡œ í‘œì‹œ
    context_hint = ""
    if last_assistant_content:
        truncated = last_assistant_content[:3000]
        if len(last_assistant_content) > 3000:
            truncated += "\n... (ì´í•˜ ìƒëµ)"
        context_hint = f"""

## ì§ì „ ì–´ì‹œìŠ¤í„´íŠ¸ ì‘ë‹µ (ê°€ì¥ ìµœê·¼ì— ë‚´ê°€ ë‹µë³€í•œ ë‚´ìš©):
\"\"\"
{truncated}
\"\"\"
"""
    
    # í˜„ì¬ ë…¸íŠ¸ ì»¨í…ìŠ¤íŠ¸
    active_note_section = ""
    if active_note_path:
        note_title = active_note_path.replace(".md", "")
        note_preview = ""
        if active_note_content:
            note_preview = active_note_content[:3000]
            if len(active_note_content) > 3000:
                note_preview += "\n... (ì´í•˜ ìƒëµ)"
        active_note_section = f"""

## í˜„ì¬ ì‚¬ìš©ìê°€ ë³´ê³  ìˆëŠ” ë…¸íŠ¸:
íŒŒì¼ê²½ë¡œ: {active_note_path}
ì œëª©: {note_title}
ë‚´ìš©:
\"\"\"
{note_preview}
\"\"\"
"""
    
    return f"""ë‹¹ì‹ ì€ CueNote ë…¸íŠ¸ ì•±ì˜ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ìš”ì²­ì— ë”°ë¼ ì•± ê¸°ëŠ¥ì„ ì‹¤í–‰í•˜ê³ , ì¹œì ˆí•˜ê²Œ ê²°ê³¼ë¥¼ ì•ˆë‚´í•©ë‹ˆë‹¤.

ì˜¤ëŠ˜ ë‚ ì§œ: {today}

ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬:
{tools_desc}

## ë§¤ìš° ì¤‘ìš”í•œ ì‘ë‹µ ê·œì¹™:

### ë„êµ¬ í˜¸ì¶œ ê·œì¹™:
1. ë„êµ¬ë¥¼ ì‹¤í–‰í•´ì•¼ í•˜ë©´ ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ **ë§Œ** ì¶œë ¥í•˜ì„¸ìš” (ë‹¤ë¥¸ í…ìŠ¤íŠ¸ ì—†ì´):
   {{"tool_call": {{"name": "ë„êµ¬ì´ë¦„", "arguments": {{"param": "value"}}}}}}
2. ë„êµ¬ê°€ í•„ìš” ì—†ëŠ” ì¼ë°˜ ëŒ€í™”ë¼ë©´, ìì—°ì–´ë¡œ ì§ì ‘ ì‘ë‹µí•˜ì„¸ìš”.
3. í•˜ë‚˜ì˜ ìš”ì²­ì— í•˜ë‚˜ì˜ tool_callë§Œ ì‚¬ìš©í•˜ì„¸ìš”.

### í˜„ì¬ ë…¸íŠ¸ ê´€ë ¨ ê·œì¹™ (ë§¤ìš° ì¤‘ìš”!):
4. ì‚¬ìš©ìê°€ "ì´ ê¸€", "ì´ ë…¸íŠ¸", "í˜„ì¬ ë…¸íŠ¸", "ì§€ê¸ˆ ë³´ê³  ìˆëŠ” ê¸€" ë“±ìœ¼ë¡œ í˜„ì¬ ë…¸íŠ¸ë¥¼ ì°¸ì¡°í•˜ë©´,
   ë°˜ë“œì‹œ "í˜„ì¬ ì‚¬ìš©ìê°€ ë³´ê³  ìˆëŠ” ë…¸íŠ¸" ì„¹ì…˜ì˜ ë‚´ìš©ì„ ì‚¬ìš©í•˜ì„¸ìš”.
5. "ì´ ê¸€ì´ ë¬´ìŠ¨ ë‚´ìš©ì´ì•¼?" â†’ read_noteë¥¼ í˜¸ì¶œí•˜ì§€ ë§ê³ , í”„ë¡¬í”„íŠ¸ì— ì´ë¯¸ í¬í•¨ëœ ë…¸íŠ¸ ë‚´ìš©ì„ ì½ê³  ìì—°ì–´ë¡œ ì§ì ‘ ì„¤ëª…í•˜ì„¸ìš”.
6. "ì´ ê¸€ ìš”ì•½í•´ì¤˜" â†’ í”„ë¡¬í”„íŠ¸ì— í¬í•¨ëœ ë…¸íŠ¸ì˜ **ì‹¤ì œ í…ìŠ¤íŠ¸ ì „ì²´**ë¥¼ summarize_textì˜ contentì— ë„£ìœ¼ì„¸ìš”. ì ˆëŒ€ "[í˜„ì¬ ë…¸íŠ¸ ë‚´ìš©]" ê°™ì€ í”Œë ˆì´ìŠ¤í™€ë”ë¥¼ ì“°ì§€ ë§ˆì„¸ìš”.
7. "ì´ ê¸€ ë²ˆì—­í•´ì¤˜" â†’ í”„ë¡¬í”„íŠ¸ì— í¬í•¨ëœ ë…¸íŠ¸ì˜ **ì‹¤ì œ í…ìŠ¤íŠ¸ ì „ì²´**ë¥¼ translate_textì˜ contentì— ë„£ìœ¼ì„¸ìš”.
8. "ì´ ê¸€ ê°œì„ í•´ì¤˜ / ìˆ˜ì •í•´ì¤˜" â†’ ë…¸íŠ¸ ë‚´ìš©ì„ ê°œì„ í•˜ì—¬ save_note(path=í˜„ì¬ê²½ë¡œ, content=ê°œì„ ëœë‚´ìš©)ë¡œ ì €ì¥
9. ì¤‘ìš”: read_note ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš” â€” í˜„ì¬ ë…¸íŠ¸ ë‚´ìš©ì€ ì´ë¯¸ í”„ë¡¬í”„íŠ¸ì— í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤!

### ëŒ€í™” ë§¥ë½ ê·œì¹™:
9. ì‚¬ìš©ìê°€ "ì´ ë‚´ìš©", "ìœ„ ë‚´ìš©", "ì´ê±¸", "ê·¸ê±°", "ë°©ê¸ˆ ë§í•œ ê²ƒ" ë“±ìœ¼ë¡œ ì´ì „ ëŒ€í™”ë¥¼ ì°¸ì¡°í•˜ë©´,
   "ì§ì „ ì–´ì‹œìŠ¤í„´íŠ¸ ì‘ë‹µ"ì˜ ë‚´ìš©ì„ ì‚¬ìš©í•˜ì„¸ìš”.

### ê¸°íƒ€ ê·œì¹™:
10. í•œêµ­ì–´ë¡œ ì‘ë‹µí•˜ì„¸ìš” (ì‚¬ìš©ìê°€ ì˜ì–´ë¡œ ë§í•˜ë©´ ì˜ì–´ë¡œ).
11. ë‚ ì§œê°€ í•„ìš”í•œ ê²½ìš°, ì˜¤ëŠ˜ ë‚ ì§œ({today}) ê¸°ì¤€ìœ¼ë¡œ íŒë‹¨í•˜ì„¸ìš”.
12. ì‚¬ìš©ìê°€ ë„êµ¬ ì‹¤í–‰ì„ ìš”ì²­í•˜ë©´ ì ˆëŒ€ ë˜ë¬»ì§€ ë§ê³  ë°”ë¡œ tool_call JSONì„ ì¶œë ¥í•˜ì„¸ìš”.
{active_note_section}{context_hint}
{f"## ì´ì „ ëŒ€í™” ê¸°ë¡:{chr(10)}{history_block}" if history_block else ""}

[ì‚¬ìš©ì]: {user_message}

[ì–´ì‹œìŠ¤í„´íŠ¸]:"""



def build_result_prompt(
    user_message: str,
    tool_name: str,
    tool_result: dict,
    history: list[ChatMessage],
) -> str:
    """ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìì—°ì–´ ì‘ë‹µ ìƒì„±"""
    result_json = json.dumps(tool_result, ensure_ascii=False, indent=2)
    
    return f"""ë‹¹ì‹ ì€ CueNote ë…¸íŠ¸ ì•±ì˜ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ìš”ì²­ì— ëŒ€í•´ ë„êµ¬ë¥¼ ì‹¤í–‰í•œ ê²°ê³¼ì…ë‹ˆë‹¤. ì´ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¹œì ˆí•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ ì‘ë‹µì„ ìƒì„±í•˜ì„¸ìš”.

ì‚¬ìš©ì ìš”ì²­: {user_message}
ì‹¤í–‰ëœ ë„êµ¬: {tool_name}
ì‹¤í–‰ ê²°ê³¼:
{result_json}

## ì‘ë‹µ ê·œì¹™:
1. ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ë¥¼ ì‚¬ìš©ìê°€ ì´í•´í•˜ê¸° ì‰½ê²Œ ìì—°ì–´ë¡œ ì„¤ëª…í•˜ì„¸ìš”.
2. í•œêµ­ì–´ë¡œ ì‘ë‹µí•˜ì„¸ìš”.
3. ê²°ê³¼ê°€ ëª©ë¡ì´ë©´ ë³´ê¸° ì¢‹ê²Œ ì •ë¦¬í•´ ì£¼ì„¸ìš”.
4. ì—ëŸ¬ê°€ ë°œìƒí•œ ê²½ìš°, ì›ì¸ê³¼ í•´ê²° ë°©ë²•ì„ ì•ˆë‚´í•˜ì„¸ìš”.
5. ê°„ê²°í•˜ê³  ì¹œì ˆí•˜ê²Œ ì‘ë‹µí•˜ì„¸ìš”.
6. ë§ˆí¬ë‹¤ìš´ í¬ë§·ì„ ì‚¬ìš©í•˜ë©´ ë” ë³´ê¸° ì¢‹ìŠµë‹ˆë‹¤.

ì‘ë‹µ:"""


def build_continuation_prompt(
    user_message: str,
    tool_history: list[dict],
    today: str
) -> str:
    """ë©€í‹°ìŠ¤í… ë„êµ¬ í˜¸ì¶œì„ ìœ„í•œ ì—°ì† í”„ë¡¬í”„íŠ¸"""
    tools_desc = build_tool_descriptions()
    
    history_text = ""
    for i, th in enumerate(tool_history, 1):
        result_str = json.dumps(th["result"], ensure_ascii=False)
        if len(result_str) > 1000:
            result_str = result_str[:1000] + "..."
        history_text += f"\në‹¨ê³„ {i}: {th['name']}({json.dumps(th['args'], ensure_ascii=False)})\nê²°ê³¼: {result_str}\n"
    
    return f"""ë‹¹ì‹ ì€ CueNote ë…¸íŠ¸ ì•±ì˜ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ì›ë˜ ìš”ì²­ì„ ì™„ì „íˆ ìˆ˜í–‰í•˜ê¸° ìœ„í•´, ì¶”ê°€ ë„êµ¬ í˜¸ì¶œì´ í•„ìš”í•œì§€ íŒë‹¨í•˜ì„¸ìš”.

ì˜¤ëŠ˜ ë‚ ì§œ: {today}

ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬:
{tools_desc}

## ì‚¬ìš©ì ì›ë˜ ìš”ì²­:
{user_message}

## ì´ë¯¸ ì‹¤í–‰ëœ ë„êµ¬:
{history_text}

## íŒë‹¨ ê·œì¹™:
1. ì‚¬ìš©ìì˜ ìš”ì²­ì´ ì•„ì§ ì™„ì „íˆ ìˆ˜í–‰ë˜ì§€ ì•Šì•˜ë‹¤ë©´, ë‹¤ìŒì— ì‹¤í–‰í•  ë„êµ¬ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:
   {{"tool_call": {{"name": "ë„êµ¬ì´ë¦„", "arguments": {{"param": "value"}}}}}}
2. ì‚¬ìš©ìì˜ ìš”ì²­ì´ ì´ë¯¸ ì™„ì „íˆ ìˆ˜í–‰ë˜ì—ˆë‹¤ë©´, "ì™„ë£Œ" ë¼ê³ ë§Œ ì‘ë‹µí•˜ì„¸ìš”.
3. ì˜ˆì‹œ: "XXë¥¼ ê²€ìƒ‰í•´ì„œ ë…¸íŠ¸ë¥¼ ë§Œë“¤ì–´ì¤˜" â†’ web_search í›„ â†’ ê·¸ ê²°ê³¼ë¡œ create_note ë„êµ¬ í˜¸ì¶œ
4. ì´ì „ ë‹¨ê³„ì˜ ê²°ê³¼ ë°ì´í„°ë¥¼ í™œìš©í•˜ì—¬ ë‹¤ìŒ ë„êµ¬ì˜ argumentsë¥¼ ì±„ìš°ì„¸ìš”.

ì‘ë‹µ:"""


def build_multistep_result_prompt(
    user_message: str,
    tool_history: list[dict],
    history: list[ChatMessage],
) -> str:
    """ë©€í‹°ìŠ¤í… ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìì—°ì–´ ì‘ë‹µ ìƒì„±"""
    steps_text = ""
    for i, th in enumerate(tool_history, 1):
        result_str = json.dumps(th["result"], ensure_ascii=False, indent=2)
        if len(result_str) > 2000:
            result_str = result_str[:2000] + "\n... (truncated)"
        steps_text += f"\n### ë‹¨ê³„ {i}: {th['name']}\nì¸ì: {json.dumps(th['args'], ensure_ascii=False)}\nê²°ê³¼:\n{result_str}\n"
    
    return f"""ë‹¹ì‹ ì€ CueNote ë…¸íŠ¸ ì•±ì˜ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ìš”ì²­ì— ëŒ€í•´ ë„êµ¬ë¥¼ ì‹¤í–‰í•œ ê²°ê³¼ì…ë‹ˆë‹¤. ì´ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¹œì ˆí•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ ì‘ë‹µì„ ìƒì„±í•˜ì„¸ìš”.

ì‚¬ìš©ì ìš”ì²­: {user_message}

## ì‹¤í–‰ëœ ë„êµ¬ë“¤:
{steps_text}

## ì‘ë‹µ ê·œì¹™:
1. ëª¨ë“  ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ì‚¬ìš©ìê°€ ì´í•´í•˜ê¸° ì‰½ê²Œ ìì—°ì–´ë¡œ ì„¤ëª…í•˜ì„¸ìš”.
2. í•œêµ­ì–´ë¡œ ì‘ë‹µí•˜ì„¸ìš”.
3. ê²°ê³¼ê°€ ëª©ë¡ì´ë©´ ë³´ê¸° ì¢‹ê²Œ ì •ë¦¬í•´ ì£¼ì„¸ìš”.
4. ì—ëŸ¬ê°€ ë°œìƒí•œ ê²½ìš°, ì›ì¸ê³¼ í•´ê²° ë°©ë²•ì„ ì•ˆë‚´í•˜ì„¸ìš”.
5. ê°„ê²°í•˜ê³  ì¹œì ˆí•˜ê²Œ ì‘ë‹µí•˜ì„¸ìš”.
6. ë§ˆí¬ë‹¤ìš´ í¬ë§·ì„ ì‚¬ìš©í•˜ë©´ ë” ë³´ê¸° ì¢‹ìŠµë‹ˆë‹¤.

ì‘ë‹µ:"""


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# LLM í˜¸ì¶œ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def call_llm_text(prompt: str, provider: str, api_key: str, model: str) -> str:
    """LLMìœ¼ë¡œ í…ìŠ¤íŠ¸ ìƒì„± (ë™ê¸°)"""
    model_or_none = model if model else None
    
    if provider == "gemini" and api_key:
        return gemini_client.generate(prompt, api_key, model_or_none)
    elif provider == "openai" and api_key:
        return openai_client.generate(prompt, api_key, model_or_none)
    elif provider == "anthropic" and api_key:
        return anthropic_client.generate(prompt, api_key, model_or_none)
    else:
        return ollama_client.generate(prompt, model=model_or_none)


def get_stream_func(prompt: str, provider: str, api_key: str, model: str):
    """LLM ìŠ¤íŠ¸ë¦¬ë° í•¨ìˆ˜ ë°˜í™˜"""
    model_or_none = model if model else None
    
    if provider == "gemini" and api_key:
        return gemini_client.stream_generate(prompt, api_key, model_or_none)
    elif provider == "openai" and api_key:
        return openai_client.stream_generate(prompt, api_key, model_or_none)
    elif provider == "anthropic" and api_key:
        return anthropic_client.stream_generate(prompt, api_key, model_or_none)
    else:
        return ollama_client.stream_generate(prompt, model_or_none)


def parse_tool_call(text: str) -> Optional[dict]:
    """LLM ì‘ë‹µì—ì„œ tool_call JSONì„ íŒŒì‹± (ê°•ê±´í•œ ë²„ì „)"""
    if "tool_call" not in text:
        return None
    
    try:
        # 1) ì „ì²´ í…ìŠ¤íŠ¸ê°€ JSONì¸ ê²½ìš°
        stripped = text.strip()
        if stripped.startswith("{") and stripped.endswith("}"):
            parsed = json.loads(stripped)
            if "tool_call" in parsed:
                return parsed["tool_call"]
        
        # 2) ```json ... ``` íŒ¨í„´
        json_match = re.search(r'```(?:json)?\s*(\{.*?\})\s*```', text, re.DOTALL)
        if json_match:
            try:
                parsed = json.loads(json_match.group(1))
                if "tool_call" in parsed:
                    return parsed["tool_call"]
            except json.JSONDecodeError:
                pass
        
        # 3) ì¤‘ì²© ê´„í˜¸ ì²˜ë¦¬ â€” "tool_call" í‚¤ì›Œë“œë¥¼ í¬í•¨í•˜ëŠ” ìµœì™¸ê³½ { } ì¶”ì¶œ
        #    ë‹¤ì–‘í•œ ì‹œì‘ íŒ¨í„´ ë§¤ì¹­ (ê³µë°±, ì¤„ë°”ê¿ˆ í—ˆìš©)
        for pattern in [r'\{\s*"tool_call"', r"\{\s*'tool_call'"]:
            match = re.search(pattern, text)
            if match:
                brace_start = match.start()
                depth = 0
                for i in range(brace_start, len(text)):
                    if text[i] == '{':
                        depth += 1
                    elif text[i] == '}':
                        depth -= 1
                        if depth == 0:
                            candidate = text[brace_start:i+1]
                            try:
                                parsed = json.loads(candidate)
                                if "tool_call" in parsed:
                                    return parsed["tool_call"]
                            except json.JSONDecodeError:
                                # ì‘ì€ë”°ì˜´í‘œë¥¼ í°ë”°ì˜´í‘œë¡œ ì¹˜í™˜ í›„ ì¬ì‹œë„
                                try:
                                    fixed = candidate.replace("'", '"')
                                    parsed = json.loads(fixed)
                                    if "tool_call" in parsed:
                                        return parsed["tool_call"]
                                except json.JSONDecodeError:
                                    pass
                            break
        
        # 4) ë§ˆì§€ë§‰ ìˆ˜ë‹¨: í…ìŠ¤íŠ¸ì—ì„œ JSON-like ë¸”ë¡ ì¶”ì¶œ ì‹œë„
        first_brace = text.find('{')
        last_brace = text.rfind('}')
        if first_brace >= 0 and last_brace > first_brace:
            candidate = text[first_brace:last_brace+1]
            try:
                parsed = json.loads(candidate)
                if "tool_call" in parsed:
                    return parsed["tool_call"]
            except json.JSONDecodeError:
                pass
        
    except (json.JSONDecodeError, KeyError, TypeError) as e:
        logger.debug(f"parse_tool_call error: {e}")
    
    return None


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# API ì—”ë“œí¬ì¸íŠ¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@router.post("/chat")
async def chat(payload: ChatPayload):
    """
    AI ì±—ë´‡ ëŒ€í™” (SSE ìŠ¤íŠ¸ë¦¬ë°)
    
    Flow:
    1. ì‚¬ìš©ì ë©”ì‹œì§€ ë¶„ì„ â†’ ë„êµ¬ í˜¸ì¶œ ì—¬ë¶€ íŒë‹¨
    2. ë„êµ¬ ì‹¤í–‰ì´ í•„ìš”í•˜ë©´ â†’ ë„êµ¬ ì‹¤í–‰ â†’ ê²°ê³¼ ê¸°ë°˜ ì‘ë‹µ ìŠ¤íŠ¸ë¦¬ë°
    3. ì¼ë°˜ ëŒ€í™”ë©´ â†’ ì§ì ‘ ì‘ë‹µ ìŠ¤íŠ¸ë¦¬ë°
    """
    user_message = payload.message.strip()
    if not user_message:
        raise HTTPException(status_code=400, detail="ë©”ì‹œì§€ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
    
    provider = payload.provider
    api_key = payload.api_key
    model = payload.model
    history = payload.history
    today = date.today().isoformat()
    
    async def event_generator():
        try:
            # 1ë‹¨ê³„: LLMì—ê²Œ ë„êµ¬ ì‚¬ìš© ì—¬ë¶€ íŒë‹¨
            chat_prompt = build_chat_prompt(
                user_message, history, today,
                active_note_path=payload.active_note_path,
                active_note_content=payload.active_note_content,
            )
            
            yield {"event": "thinking", "data": "ë©”ì‹œì§€ë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤..."}
            
            # ë™ê¸° í˜¸ì¶œë¡œ ë„êµ¬ íŒë‹¨
            llm_response = call_llm_text(chat_prompt, provider, api_key, model)
            logger.info(f"Chatbot LLM response: {llm_response[:200]}")
            
            # 2ë‹¨ê³„: tool_call íŒŒì‹±
            tool_call_data = parse_tool_call(llm_response)
            
            if tool_call_data:
                # â”€â”€â”€ ë©€í‹°ìŠ¤í… ë„êµ¬ ì‹¤í–‰ ë£¨í”„ (ìµœëŒ€ 3ë‹¨ê³„) â”€â”€â”€
                tool_history = []  # ì‹¤í–‰ëœ ë„êµ¬ë“¤ì˜ ê¸°ë¡
                MAX_STEPS = 3
                
                for step in range(MAX_STEPS):
                    tool_name = tool_call_data.get("name", "")
                    tool_args = tool_call_data.get("arguments", {})
                    
                    logger.info(f"Chatbot tool call [{step+1}]: {tool_name}({tool_args})")
                    
                    # ë„êµ¬ í˜¸ì¶œ ì •ë³´ ì „ì†¡
                    yield {
                        "event": "tool_call",
                        "data": json.dumps({
                            "name": tool_name,
                            "arguments": tool_args
                        }, ensure_ascii=False)
                    }
                    
                    # ë„êµ¬ ì‹¤í–‰
                    tool_result = await execute_tool(
                        tool_name, tool_args, provider, api_key, model
                    )
                    
                    yield {
                        "event": "tool_result",
                        "data": json.dumps(tool_result, ensure_ascii=False)
                    }
                    
                    tool_history.append({
                        "name": tool_name,
                        "args": tool_args,
                        "result": tool_result
                    })
                    
                    # ë‹¤ìŒ ë‹¨ê³„ íŒë‹¨: LLMì—ê²Œ ì¶”ê°€ ë„êµ¬ í˜¸ì¶œì´ í•„ìš”í•œì§€ í™•ì¸
                    if step < MAX_STEPS - 1:
                        continuation_prompt = build_continuation_prompt(
                            user_message, tool_history, today
                        )
                        cont_response = call_llm_text(continuation_prompt, provider, api_key, model)
                        logger.info(f"Chatbot continuation [{step+1}]: {cont_response[:150]}")
                        
                        next_tool = parse_tool_call(cont_response)
                        if next_tool:
                            tool_call_data = next_tool
                            yield {"event": "thinking", "data": "ì¶”ê°€ ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤..."}
                        else:
                            break
                    else:
                        break
                
                # ìµœì¢… ê²°ê³¼ ê¸°ë°˜ ìì—°ì–´ ì‘ë‹µ (ìŠ¤íŠ¸ë¦¬ë°)
                result_prompt = build_multistep_result_prompt(
                    user_message, tool_history, history
                )
                
                stream_func = get_stream_func(result_prompt, provider, api_key, model)
                async for chunk in stream_func:
                    escaped_chunk = chunk.replace('\n', '\\n')
                    yield {"event": "message", "data": escaped_chunk}
            else:
                # ë„êµ¬ í˜¸ì¶œ ì—†ì´ ì§ì ‘ ì‘ë‹µ â€” ì´ë¯¸ ìƒì„±ëœ í…ìŠ¤íŠ¸ë¥¼ ê·¸ëŒ€ë¡œ ìŠ¤íŠ¸ë¦¬ë°
                logger.info("Chatbot: no tool call, streaming existing response")
                
                chunk_size = 8
                for i in range(0, len(llm_response), chunk_size):
                    chunk = llm_response[i:i + chunk_size]
                    escaped_chunk = chunk.replace('\n', '\\n')
                    yield {"event": "message", "data": escaped_chunk}
            
            yield {"event": "done", "data": ""}
            
        except Exception as e:
            logger.error(f"Chatbot error: {e}")
            yield {"event": "error", "data": str(e)}
    
    return EventSourceResponse(event_generator())
