"""
CueNote Core - AI ë¼ìš°í„°
ìš”ì•½, ë²ˆì—­, ë‹¤ë“¬ê¸°, ìŠ¤íŠ¸ë¦¬ë° ë“± AI ê¸°ëŠ¥
Ollama ë° Gemini API ì§€ì›
"""
from typing import Optional, cast, Literal
from fastapi import APIRouter, HTTPException
from sse_starlette.sse import EventSourceResponse

from ..config import logger
from .. import ollama_client
from .. import gemini_client
from .. import openai_client
from .. import anthropic_client
from ..schemas import (
    SummarizePayload, SummarizeResponse,
    TranslatePayload, TranslateResponse,
    ImprovePayload, ImproveResponse,
    ExpandPayload, ExpandResponse,
    ShortenPayload, ShortenResponse,
    ProofreadPayload, ProofreadResponse, CorrectionItem,
    StreamPayload,
    DocumentExtractPayload, DocumentExtractResponse,
    URLExtractPayload, URLExtractResponse,
    OCRModelStatus, OCRDownloadResponse,
)

# ê¸°ì¡´ í˜¸í™˜ì„±ì„ ìœ„í•œ import
from ..ollama_client import process_long_text, MAX_INPUT_CHARS

# MCP í†µí•©
from .mcp_integration import try_mcp_enhance


def call_json_with_provider(
    prompt: str,
    schema_hint: str,
    provider: str = "ollama",
    api_key: str = "",
    model: Optional[str] = None
):
    """LLM ì œê³µìì— ë”°ë¼ ì ì ˆí•œ í´ë¼ì´ì–¸íŠ¸ë¡œ JSON í˜¸ì¶œ"""
    if provider == "gemini" and api_key:
        return gemini_client.call_json(prompt, schema_hint, api_key, model)
    elif provider == "openai" and api_key:
        return openai_client.call_json(prompt, schema_hint, api_key, model)
    elif provider == "anthropic" and api_key:
        return anthropic_client.call_json(prompt, schema_hint, api_key, model)
    else:
        return ollama_client.call_json(prompt, schema_hint, model)

router = APIRouter(prefix="/ai", tags=["ai"])


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ìš”ì•½
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@router.post("/summarize", response_model=SummarizeResponse)
async def summarize_note(payload: SummarizePayload):
    """ë…¸íŠ¸ ë‚´ìš©ì„ ìš”ì•½í•©ë‹ˆë‹¤."""
    content = payload.content.strip()
    
    if not content:
        raise HTTPException(status_code=400, detail="Content is empty")
    
    content, truncation_warning = process_long_text(content)
    word_count = len(content.split())
    
    if word_count < 20:
        return SummarizeResponse(summary=content, keyPoints=[], wordCount=word_count)
    
    # ì–¸ì–´ ì„¤ì •: autoì´ë©´ ì›ë¬¸ê³¼ ê°™ì€ ì–¸ì–´ë¡œ ì‘ë‹µ
    if payload.language == "auto":
        lang_instruction = "in the SAME language as the input text"
    elif payload.language == "ko":
        lang_instruction = "í•œêµ­ì–´ë¡œ"
    else:
        lang_instruction = f"in {payload.language}"
    
    prompt = (
        f"You are a helpful assistant that summarizes notes. Respond {lang_instruction}.\n"
        "Output MUST be JSON only and match the schema.\n\n"
        "Rules:\n"
        "- summary: A concise 2-3 sentence summary of the main content\n"
        "- keyPoints: Up to 5 bullet points highlighting the most important information\n"
        "- Be accurate and preserve the key meaning\n"
        "- IMPORTANT: Match the language of the input text when language is 'auto'\n\n"
        f"Note content:\n{content}\n\n"
        "Schema:\n"
        '{\n  "summary": "string",\n  "keyPoints": ["string"]\n}\n'
        "Return JSON only."
    )
    
    try:
        # MCP ë„êµ¬ í™œìš© ì‹œë„
        mcp_result = await try_mcp_enhance(content, "summarize")
        mcp_used = mcp_result.get("mcp_used", [])

        result = call_json_with_provider(
            prompt,
            "SummarizeResult with fields summary, keyPoints",
            provider=payload.provider,
            api_key=payload.api_key,
            model=payload.model if payload.model else None
        )
        summary = result.get("summary", "ìš”ì•½ ìƒì„± ì‹¤íŒ¨")
        if truncation_warning:
            summary = f"{summary}\n\n{truncation_warning}"
        
        response_data = {
            "summary": summary,
            "keyPoints": result.get("keyPoints", []),
            "wordCount": word_count,
        }
        # MCP ë„êµ¬ê°€ ì‚¬ìš©ëœ ê²½ìš° ì‘ë‹µì— í¬í•¨
        if mcp_used:
            response_data["mcp_used"] = mcp_used
            logger.info("MCP tools used in summarize: %s", [t['tool'] for t in mcp_used])
        return response_data
    except Exception as e:
        logger.error("Summarize failed: %s", e)
        raise HTTPException(status_code=500, detail="Failed to generate summary")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë²ˆì—­
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@router.post("/translate", response_model=TranslateResponse)
async def translate_text(payload: TranslatePayload):
    """ì„ íƒëœ í…ìŠ¤íŠ¸ë¥¼ ì§€ì •ëœ ì–¸ì–´ë¡œ ë²ˆì—­í•©ë‹ˆë‹¤."""
    content = payload.content.strip()
    
    if not content:
        raise HTTPException(status_code=400, detail="Content is empty")
    
    content, truncation_warning = process_long_text(content)
    
    language_names = {
        "ko": "Korean", "en": "English", "ja": "Japanese",
        "zh": "Chinese", "es": "Spanish", "fr": "French", "de": "German"
    }
    target_lang_name = language_names.get(payload.target_language, payload.target_language)
    
    prompt = (
        f"Translate the following text to {target_lang_name}.\n"
        "Output MUST be JSON only and match the schema.\n\n"
        "CRITICAL RULES:\n"
        "- PRESERVE ALL MARKDOWN FORMATTING exactly as-is\n"
        "- Only translate the actual text content, not URLs or special markers\n"
        "- Preserve the original meaning and tone\n"
        "- Detect the source language\n\n"
        f"Text to translate:\n{content}\n\n"
        "Schema:\n"
        '{\n  "translated": "string",\n  "source_language": "string"\n}\n'
        "Return JSON only."
    )
    
    try:
        result = call_json_with_provider(
            prompt,
            "TranslateResult with fields translated, source_language",
            provider=payload.provider,
            api_key=payload.api_key,
            model=payload.model if payload.model else None
        )
        translated = result.get("translated", content)
        if truncation_warning:
            translated = f"{translated}\n\n{truncation_warning}"
        return TranslateResponse(
            translated=translated,
            source_language=result.get("source_language", "unknown")
        )
    except Exception as e:
        logger.error("Translate failed: %s", e)
        raise HTTPException(status_code=500, detail="Failed to translate text")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ê¸€ ë‹¤ë“¬ê¸°
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@router.post("/improve", response_model=ImproveResponse)
async def improve_text(payload: ImprovePayload):
    """ì„ íƒëœ í…ìŠ¤íŠ¸ì˜ ë¬¸ì¥ì„ ê°œì„ í•©ë‹ˆë‹¤."""
    content = payload.content.strip()
    
    if not content:
        raise HTTPException(status_code=400, detail="Content is empty")
    
    content, truncation_warning = process_long_text(content)
    
    style_instructions = {
        "professional": "Make it more professional and polished",
        "casual": "Make it more casual and friendly",
        "academic": "Make it more formal and academic",
        "creative": "Make it more creative and engaging",
        "concise": "Make it more concise and clear",
        "detailed": "Add more detail and explanation"
    }
    style_inst = style_instructions.get(payload.style, style_instructions["professional"])
    
    # ì–¸ì–´ ì„¤ì •: autoì´ë©´ ì›ë¬¸ê³¼ ê°™ì€ ì–¸ì–´ë¡œ ì‘ë‹µ
    if payload.language == "auto":
        lang_instruction = "Write in the SAME language as the input text"
    elif payload.language == "ko":
        lang_instruction = "í•œêµ­ì–´ë¡œ ì‘ì„±"
    else:
        lang_instruction = f"Write in {payload.language}"
    
    prompt = (
        f"Improve the following text. {style_inst}. {lang_instruction}.\n"
        "Output MUST be JSON only and match the schema.\n\n"
        "CRITICAL RULES:\n"
        "- PRESERVE ALL MARKDOWN FORMATTING exactly as-is\n"
        "- Improve grammar, clarity, and flow\n"
        "- Preserve the original meaning\n"
        "- List 2-3 key changes made\n"
        "- IMPORTANT: Match the language of the input text when language is 'auto'\n\n"
        f"Text to improve:\n{content}\n\n"
        "Schema:\n"
        '{\n  "improved": "string",\n  "changes": ["string"]\n}\n'
        "Return JSON only."
    )
    
    try:
        result = call_json_with_provider(
            prompt,
            "ImproveResult with fields improved, changes",
            provider=payload.provider,
            api_key=payload.api_key,
            model=payload.model if payload.model else None
        )
        improved = result.get("improved", content)
        if truncation_warning:
            improved = f"{improved}\n\n{truncation_warning}"
        return ImproveResponse(
            improved=improved,
            changes=result.get("changes", [])
        )
    except Exception as e:
        logger.error("Improve failed: %s", e)
        raise HTTPException(status_code=500, detail="Failed to improve text")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# í™•ì¥
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@router.post("/expand", response_model=ExpandResponse)
async def expand_text(payload: ExpandPayload):
    """ì„ íƒëœ í…ìŠ¤íŠ¸ë¥¼ ë” ìì„¸í•˜ê²Œ í™•ì¥í•©ë‹ˆë‹¤."""
    content = payload.content.strip()
    
    if not content:
        raise HTTPException(status_code=400, detail="Content is empty")
    
    content, truncation_warning = process_long_text(content, max_chars=8000)
    
    # ì–¸ì–´ ì„¤ì •: autoì´ë©´ ì›ë¬¸ê³¼ ê°™ì€ ì–¸ì–´ë¡œ ì‘ë‹µ
    if payload.language == "auto":
        lang_instruction = "Write in the SAME language as the input text"
    elif payload.language == "ko":
        lang_instruction = "í•œêµ­ì–´ë¡œ ì‘ì„±"
    else:
        lang_instruction = f"Write in {payload.language}"
    
    prompt = (
        f"Expand and elaborate on the following text. {lang_instruction}.\n"
        "Output MUST be JSON only and match the schema.\n\n"
        "CRITICAL RULES:\n"
        "- PRESERVE ALL MARKDOWN FORMATTING exactly as-is\n"
        "- Add more detail and explanation\n"
        "- Keep the same tone and style\n"
        "- Make it about 2-3x longer\n"
        "- IMPORTANT: Match the language of the input text when language is 'auto'\n\n"
        f"Text to expand:\n{content}\n\n"
        "Schema:\n"
        '{\n  "expanded": "string"\n}\n'
        "Return JSON only."
    )
    
    try:
        result = call_json_with_provider(
            prompt,
            "ExpandResult with field expanded",
            provider=payload.provider,
            api_key=payload.api_key,
            model=payload.model if payload.model else None
        )
        expanded = result.get("expanded", content)
        if truncation_warning:
            expanded = f"{expanded}\n\n{truncation_warning}"
        return ExpandResponse(expanded=expanded)
    except Exception as e:
        logger.error("Expand failed: %s", e)
        raise HTTPException(status_code=500, detail="Failed to expand text")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì¶•ì•½
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@router.post("/shorten", response_model=ShortenResponse)
async def shorten_text(payload: ShortenPayload):
    """ì„ íƒëœ í…ìŠ¤íŠ¸ë¥¼ ë” ê°„ê²°í•˜ê²Œ ì¶•ì•½í•©ë‹ˆë‹¤."""
    content = payload.content.strip()
    
    if not content:
        raise HTTPException(status_code=400, detail="Content is empty")
    
    content, truncation_warning = process_long_text(content)
    
    # ì–¸ì–´ ì„¤ì •: autoì´ë©´ ì›ë¬¸ê³¼ ê°™ì€ ì–¸ì–´ë¡œ ì‘ë‹µ
    if payload.language == "auto":
        lang_instruction = "Write in the SAME language as the input text"
    elif payload.language == "ko":
        lang_instruction = "í•œêµ­ì–´ë¡œ ì‘ì„±"
    else:
        lang_instruction = f"Write in {payload.language}"
    
    prompt = (
        f"Shorten and condense the following text. {lang_instruction}.\n"
        "Output MUST be JSON only and match the schema.\n\n"
        "CRITICAL RULES:\n"
        "- PRESERVE ALL MARKDOWN FORMATTING exactly as-is\n"
        "- Keep the essential meaning\n"
        "- Remove redundancy\n"
        "- Make it about half the length\n"
        "- IMPORTANT: Match the language of the input text when language is 'auto'\n\n"
        f"Text to shorten:\n{content}\n\n"
        "Schema:\n"
        '{\n  "shortened": "string"\n}\n'
        "Return JSON only."
    )
    
    try:
        result = call_json_with_provider(
            prompt,
            "ShortenResult with field shortened",
            provider=payload.provider,
            api_key=payload.api_key,
            model=payload.model if payload.model else None
        )
        shortened = result.get("shortened", content)
        if truncation_warning:
            shortened = f"{shortened}\n\n{truncation_warning}"
        return ShortenResponse(shortened=shortened)
    except Exception as e:
        logger.error("Shorten failed: %s", e)
        raise HTTPException(status_code=500, detail="Failed to shorten text")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë§ì¶¤ë²• êµì •
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@router.post("/proofread", response_model=ProofreadResponse)
async def proofread_text(payload: ProofreadPayload):
    """ì„ íƒëœ í…ìŠ¤íŠ¸ì˜ ë§ì¶¤ë²•ê³¼ ë¬¸ë²•ì„ êµì •í•©ë‹ˆë‹¤. í•œêµ­ì–´ì™€ ì˜ì–´ë¥¼ ì§€ì›í•©ë‹ˆë‹¤."""
    content = payload.content.strip()
    
    if not content:
        raise HTTPException(status_code=400, detail="Content is empty")
    
    content, truncation_warning = process_long_text(content)
    
    prompt = (
        "You are a professional proofreader. Find and fix spelling, grammar, and punctuation errors.\n"
        "Output MUST be JSON only and match the schema.\n\n"
        "CRITICAL RULES:\n"
        "- PRESERVE ALL MARKDOWN FORMATTING exactly as-is (headers, lists, bold, italic, links, code)\n"
        "- Find ALL errors including:\n"
        "  * Spelling mistakes (e.g., 'ì•ˆë…•í•˜ì„¸ìš§' â†’ 'ì•ˆë…•í•˜ì„¸ìš”', 'teh' â†’ 'the')\n"
        "  * Grammar errors (e.g., subject-verb agreement, tense)\n"
        "  * Punctuation (e.g., missing periods, incorrect comma usage)\n"
        "  * Spacing issues (e.g., 'ì•ˆë…• í•˜ì„¸ìš”' â†’ 'ì•ˆë…•í•˜ì„¸ìš”', 'helloworld' â†’ 'hello world')\n"
        "- DO NOT change the meaning or style of the text\n"
        "- DO NOT translate - keep the original language\n"
        "- If text mixes Korean and English, fix each language according to its rules\n"
        "- Return EACH error as a separate item in the 'items' array\n"
        "- For each item, provide: original text, corrected text, reason, and type\n"
        "- Type must be one of: 'spelling', 'grammar', 'punctuation', 'spacing'\n"
        "- If there are no errors, return empty items array\n\n"
        f"Text to proofread:\n{content}\n\n"
        "Schema:\n"
        '{\n'
        '  "corrected": "string (the full corrected text)",\n'
        '  "items": [\n'
        '    {\n'
        '      "original": "wrong word or phrase",\n'
        '      "corrected": "correct word or phrase",\n'
        '      "reason": "brief explanation (in same language as the error)",\n'
        '      "type": "spelling|grammar|punctuation|spacing"\n'
        '    }\n'
        '  ],\n'
        '  "language_detected": "ko|en|mixed"\n'
        '}\n'
        "Return JSON only."
    )
    
    try:
        result = call_json_with_provider(
            prompt,
            "ProofreadResult with fields corrected, items, language_detected",
            provider=payload.provider,
            api_key=payload.api_key,
            model=payload.model if payload.model else None
        )
        corrected = result.get("corrected", content)
        if truncation_warning:
            corrected = f"{corrected}\n\n{truncation_warning}"
        
        # items íŒŒì‹±
        raw_items = result.get("items", [])
        items = []
        for item in raw_items:
            if isinstance(item, dict) and "original" in item and "corrected" in item:
                items.append(CorrectionItem(
                    original=item.get("original", ""),
                    corrected=item.get("corrected", ""),
                    reason=item.get("reason", ""),
                    type=item.get("type", "spelling")
                ))
        
        return ProofreadResponse(
            corrected=corrected,
            items=items,
            language_detected=result.get("language_detected", "")
        )
    except Exception as e:
        logger.error("Proofread failed: %s", e)
        raise HTTPException(status_code=500, detail="Failed to proofread text")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ìŠ¤íŠ¸ë¦¬ë°
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def build_stream_prompt(payload: StreamPayload) -> str:
    """ìŠ¤íŠ¸ë¦¬ë°ìš© í”„ë¡¬í”„íŠ¸ ìƒì„±"""
    content = payload.content
    
    preserve_rules = (
        "CRITICAL RULES:\n"
        "- Output ONLY the result text, no explanations or comments\n"
        "- PRESERVE ALL SPACES between words exactly as normal text\n"
        "- PRESERVE ALL LINE BREAKS and paragraph structure\n"
        "- PRESERVE ALL MARKDOWN FORMATTING exactly:\n"
        "  * Headers: # ## ### etc.\n"
        "  * Lists: - item or * item\n"
        "  * Checkboxes: - [ ] or - [x]\n"
        "  * Bold: **text**\n"
        "  * Italic: *text*\n"
        "  * Links: [text](url)\n"
        "  * Code: `code` or ```code```\n"
        "- Write naturally with proper spacing between words\n"
    )
    
    if payload.action == "translate":
        language_names = {
            "ko": "Korean (í•œêµ­ì–´)", "en": "English", "ja": "Japanese (æ—¥æœ¬èª)",
            "zh": "Chinese (ä¸­æ–‡)", "es": "Spanish (EspaÃ±ol)", "fr": "French (FranÃ§ais)", "de": "German (Deutsch)"
        }
        target_lang = language_names.get(payload.target_language, payload.target_language)
        
        korean_instruction = ""
        if payload.target_language == "ko":
            korean_instruction = (
                "\nKOREAN TRANSLATION RULES:\n"
                "- Use ONLY Hangul (Korean alphabet) for the translation\n"
                "- Do NOT use Chinese characters (æ¼¢å­—/í•œì) - convert them to Hangul\n"
                "- Do NOT use Japanese characters (ã²ã‚‰ãŒãª/ã‚«ã‚¿ã‚«ãƒŠ) - translate to Korean\n"
                "- Common conversions: æ—¥ â†’ ì¼, æœˆ â†’ ì›”, å¹´ â†’ ë…„, ä¸­ â†’ ì¤‘\n"
                "- Write all Korean words in pure Hangul script\n"
            )
        
        return (
            f"Translate the following text to {target_lang}.\n"
            f"{preserve_rules}"
            f"{korean_instruction}\n"
            f"---INPUT---\n{content}\n---OUTPUT ({target_lang})---\n"
        )
    
    elif payload.action == "improve":
        style_instructions = {
            "professional": "more professional",
            "casual": "more casual and friendly",
            "academic": "more academic",
            "creative": "more creative",
            "concise": "more concise",
            "detailed": "more detailed"
        }
        style_inst = style_instructions.get(payload.style, style_instructions["professional"])
        return (
            f"Rewrite the following text to be {style_inst}. Keep the same language.\n"
            f"{preserve_rules}\n"
            f"---INPUT---\n{content}\n---OUTPUT---\n"
        )
    
    elif payload.action == "expand":
        return (
            f"Expand the following text with more details. Make it 2-3x longer. Keep the same language.\n"
            f"{preserve_rules}\n"
            f"---INPUT---\n{content}\n---OUTPUT---\n"
        )
    
    elif payload.action == "shorten":
        return (
            f"Shorten the following text to about half the length. Keep key points. Keep the same language.\n"
            f"{preserve_rules}\n"
            f"---INPUT---\n{content}\n---OUTPUT---\n"
        )
    
    elif payload.action == "summarize":
        return (
            f"Summarize the following text in 2-3 sentences. Keep the same language.\n"
            f"{preserve_rules}\n"
            f"---INPUT---\n{content}\n---SUMMARY---\n"
        )
    
    elif payload.action == "proofread":
        return (
            f"Proofread and correct spelling, grammar, and punctuation errors in the following text.\n"
            f"{preserve_rules}"
            "- Fix spelling mistakes (e.g., 'ì•ˆë…•í•˜ì„¸ìš§' â†’ 'ì•ˆë…•í•˜ì„¸ìš”', 'teh' â†’ 'the')\n"
            "- Fix grammatical errors while preserving meaning\n"
            "- Fix punctuation and spacing issues\n"
            "- DO NOT translate - keep the original language\n"
            "- If text mixes Korean and English, fix each language according to its rules\n\n"
            f"---INPUT---\n{content}\n---CORRECTED---\n"
        )
    
    elif payload.action == "custom":
        # ì‚¬ìš©ì ì •ì˜ í”„ë¡¬í”„íŠ¸
        user_instruction = payload.custom_prompt or "Edit the text as requested"
        
        # ì„ íƒëœ í…ìŠ¤íŠ¸ê°€ ìˆëŠ” ê²½ìš°ì™€ ì—†ëŠ” ê²½ìš° êµ¬ë¶„
        if content.strip():
            return (
                f"You are a helpful writing assistant. Follow the user's instruction exactly.\n"
                f"{preserve_rules}\n"
                f"USER INSTRUCTION: {user_instruction}\n\n"
                f"Apply this instruction to the following text:\n"
                f"---INPUT TEXT---\n{content}\n---OUTPUT---\n"
            )
        else:
            # ì„ íƒëœ í…ìŠ¤íŠ¸ ì—†ì´ ìƒˆ ê¸€ ìƒì„±
            return (
                f"You are a helpful writing assistant that writes high-quality content.\n"
                f"{preserve_rules}\n"
                f"IMPORTANT: Generate NEW content based on the user's request. Write naturally and creatively.\n"
                f"Match the language of the user's instruction (if Korean instruction, write in Korean).\n\n"
                f"USER REQUEST: {user_instruction}\n\n"
                f"---OUTPUT---\n"
            )
    
    else:
        raise ValueError(f"Unknown action: {payload.action}")


@router.post("/stream")
async def ai_stream(payload: StreamPayload):
    """ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ AI í…ìŠ¤íŠ¸ ìƒì„± (SSE)"""
    content = payload.content.strip()
    
    # custom actionì€ content ì—†ì´ë„ í—ˆìš© (ìƒˆ ê¸€ ìƒì„±)
    if not content and payload.action != "custom":
        raise HTTPException(status_code=400, detail="Content is empty")
    
    max_chars = 8000 if payload.action == "expand" else MAX_INPUT_CHARS
    content, truncation_warning = process_long_text(content, max_chars)
    payload.content = content
    
    try:
        prompt = build_stream_prompt(payload)
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    
    # LLM ì œê³µìì— ë”°ë¥¸ ìŠ¤íŠ¸ë¦¬ë° í•¨ìˆ˜ ì„ íƒ
    provider = payload.provider
    api_key = payload.api_key
    model = payload.model if payload.model else None
    
    async def event_generator():
        try:
            # MCP ë„êµ¬ í™œìš© ì‹œë„ (ìŠ¤íŠ¸ë¦¬ë° ì „ì—)
            mcp_result = await try_mcp_enhance(content, payload.action)
            mcp_used = mcp_result.get("mcp_used", [])
            if mcp_used:
                import json
                yield {"event": "mcp", "data": json.dumps(mcp_used)}

            # LLM ì œê³µìì— ë”°ë¥¸ ìŠ¤íŠ¸ë¦¬ë° í•¨ìˆ˜ ì„ íƒ
            if provider == "gemini" and api_key:
                stream_func = gemini_client.stream_generate(prompt, api_key, model)
            elif provider == "openai" and api_key:
                stream_func = openai_client.stream_generate(prompt, api_key, model)
            elif provider == "anthropic" and api_key:
                stream_func = anthropic_client.stream_generate(prompt, api_key, model)
            else:
                stream_func = ollama_client.stream_generate(prompt, model)
            
            async for chunk in stream_func:
                escaped_chunk = chunk.replace('\n', '\\n')
                yield {"event": "message", "data": escaped_chunk}
            
            if truncation_warning:
                yield {"event": "warning", "data": truncation_warning}
            yield {"event": "done", "data": ""}
            
        except Exception as e:
            logger.error(f"Streaming error: {e}")
            yield {"event": "error", "data": str(e)}
    
    return EventSourceResponse(event_generator())


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë¬¸ì„œ ì¶”ì¶œ (PDF/ì´ë¯¸ì§€ â†’ ë§ˆí¬ë‹¤ìš´)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def extract_text_from_pdf(pdf_data: str) -> tuple[str, int]:
    """
    PDFì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
    
    Args:
        pdf_data: Base64 ì¸ì½”ë”©ëœ PDF ë°ì´í„°
    
    Returns:
        (ì¶”ì¶œëœ í…ìŠ¤íŠ¸, í˜ì´ì§€ ìˆ˜)
    """
    import base64
    import io
    
    try:
        import fitz  # PyMuPDF
    except ImportError:
        raise ImportError("PyMuPDF is required for PDF processing. Install with: pip install PyMuPDF")
    
    # Base64 ë””ì½”ë”©
    if pdf_data.startswith("data:"):
        _, base64_content = pdf_data.split(",", 1)
    else:
        base64_content = pdf_data
    
    pdf_bytes = base64.b64decode(base64_content)
    
    # PDF ì—´ê¸°
    doc = fitz.open(stream=pdf_bytes, filetype="pdf")
    page_count = len(doc)
    
    text_parts = []
    for page_num, page in enumerate(doc, 1):  # type: ignore[arg-type]
        text = page.get_text("text")
        if text.strip():
            text_parts.append(f"<!-- í˜ì´ì§€ {page_num} -->\n{text}")
    
    doc.close()
    
    return "\n\n".join(text_parts), page_count


def format_text_as_markdown(
    text: str,
    provider: str,
    api_key: str,
    language: str,
    model: Optional[str] = None
) -> str:
    """
    ì¶”ì¶œëœ í…ìŠ¤íŠ¸ë¥¼ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ì •ë¦¬
    """
    # ì–¸ì–´ ì„¤ì •: autoì´ë©´ ì›ë¬¸ê³¼ ê°™ì€ ì–¸ì–´ë¡œ ì‘ë‹µ
    if language == "auto":
        lang_instruction = "Write in the SAME language as the input text"
    elif language == "ko":
        lang_instruction = "í•œêµ­ì–´ë¡œ ì‘ì„±"
    else:
        lang_instruction = f"Write in {language}"
    
    prompt = f"""You are a document converter. Convert the following text into clean markdown format.

RULES (DO NOT output these rules, just follow them):
- Use appropriate headings (#, ##, ###)
- Convert lists to markdown lists (-, 1.)
- Convert tables to markdown tables
- Use **bold** for important content, *italic* for emphasis
- Wrap code in code blocks
- Remove unnecessary whitespace
- Output ONLY the converted markdown, nothing else
- {lang_instruction}

---INPUT TEXT---
{text}
---END INPUT---

Output the markdown below (no explanations, no instructions, just the converted content):"""
    
    if provider == "gemini" and api_key:
        return gemini_client.generate(prompt, api_key, model)
    elif provider == "openai" and api_key:
        return openai_client.generate(prompt, api_key, model)
    elif provider == "anthropic" and api_key:
        return anthropic_client.generate(prompt, api_key, model)
    else:
        return ollama_client.generate(prompt, model=model)


@router.post("/extract", response_model=DocumentExtractResponse)
async def extract_document(payload: DocumentExtractPayload):
    """
    PDF ë˜ëŠ” ì´ë¯¸ì§€ì—ì„œ ë§ˆí¬ë‹¤ìš´ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    
    - PDF: PyMuPDFë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (ì‹¤íŒ¨ ì‹œ OCR) í›„ LLMìœ¼ë¡œ ë§ˆí¬ë‹¤ìš´ í˜•ì‹í™”
    - ì´ë¯¸ì§€: EasyOCRë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ í›„ LLMìœ¼ë¡œ ë§ˆí¬ë‹¤ìš´ í˜•ì‹í™”
    """
    from .. import ocr_client
    
    file_data = payload.file_data.strip()
    
    if not file_data:
        raise HTTPException(status_code=400, detail="File data is empty")
    
    try:
        if payload.file_type == "pdf":
            # PDF ì²˜ë¦¬: ë¨¼ì € í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹œë„
            raw_text, page_count = extract_text_from_pdf(file_data)
            
            # í…ìŠ¤íŠ¸ê°€ ì—†ìœ¼ë©´ OCRë¡œ fallback
            if not raw_text.strip():
                logger.info("PDF text extraction failed, falling back to OCR...")
                try:
                    # OCR ì—”ì§„ ì„ íƒì— ë”°ë¼ ì²˜ë¦¬
                    ocr_engine = payload.ocr_engine or "rapidocr"
                    raw_text, page_count = ocr_client.extract_text_from_pdf_images(
                        file_data,
                        engine=cast(Literal["gemini", "rapidocr"], ocr_engine),
                        api_key=payload.api_key if ocr_engine == "gemini" else None,
                        gemini_model=payload.model if ocr_engine == "gemini" else None,
                    )
                except ImportError as e:
                    raise HTTPException(
                        status_code=500,
                        detail=f"OCR ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤: {str(e)}"
                    )
                except ValueError as e:
                    raise HTTPException(
                        status_code=400,
                        detail=str(e)
                    )
                
                if not raw_text.strip():
                    raise HTTPException(
                        status_code=400, 
                        detail="PDFì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                    )
            
            # í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¸¸ë©´ ì˜ë¼ë‚´ê¸°
            if len(raw_text) > MAX_INPUT_CHARS * 2:
                raw_text = raw_text[:MAX_INPUT_CHARS * 2]
                logger.warning(f"PDF text truncated to {MAX_INPUT_CHARS * 2} chars")
            
            # raw_text_only ì˜µì…˜: AI ì—†ì´ í…ìŠ¤íŠ¸ë§Œ ë°˜í™˜
            if payload.raw_text_only:
                # ê¸°ë³¸ì ì¸ ë§ˆí¬ë‹¤ìš´ í˜•ì‹í™” (ì¤„ë°”ê¿ˆ ìœ ì§€)
                markdown = raw_text.strip()
                return DocumentExtractResponse(
                    markdown=markdown,
                    page_count=page_count,
                    has_images=False
                )
            
            # LLMìœ¼ë¡œ ë§ˆí¬ë‹¤ìš´ í˜•ì‹í™”
            markdown = format_text_as_markdown(
                raw_text,
                payload.provider,
                payload.api_key,
                payload.language,
                payload.model if payload.model else None
            )
            
            return DocumentExtractResponse(
                markdown=markdown,
                page_count=page_count,
                has_images=False
            )
        
        elif payload.file_type == "image":
            # ì´ë¯¸ì§€ ì²˜ë¦¬ (ì„ íƒëœ OCR ì—”ì§„ ì‚¬ìš©)
            try:
                ocr_engine = payload.ocr_engine or "rapidocr"
                raw_text = ocr_client.extract_text_from_base64_image(
                    file_data,
                    engine=cast(Literal["gemini", "rapidocr"], ocr_engine),
                    api_key=payload.api_key if ocr_engine == "gemini" else None,
                    gemini_model=payload.model if ocr_engine == "gemini" else None,
                )
            except ImportError as e:
                raise HTTPException(
                    status_code=500,
                    detail=f"OCR ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤: {str(e)}"
                )
            except ValueError as e:
                raise HTTPException(
                    status_code=400,
                    detail=str(e)
                )
            
            if not raw_text.strip():
                raise HTTPException(
                    status_code=400,
                    detail="ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                )
            
            # í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¸¸ë©´ ì˜ë¼ë‚´ê¸°
            if len(raw_text) > MAX_INPUT_CHARS * 2:
                raw_text = raw_text[:MAX_INPUT_CHARS * 2]
                logger.warning(f"Image text truncated to {MAX_INPUT_CHARS * 2} chars")
            
            # raw_text_only ì˜µì…˜: AI ì—†ì´ í…ìŠ¤íŠ¸ë§Œ ë°˜í™˜
            if payload.raw_text_only:
                markdown = raw_text.strip()
                return DocumentExtractResponse(
                    markdown=markdown,
                    page_count=1,
                    has_images=False
                )
            
            # LLMìœ¼ë¡œ ë§ˆí¬ë‹¤ìš´ í˜•ì‹í™”
            markdown = format_text_as_markdown(
                raw_text,
                payload.provider,
                payload.api_key,
                payload.language,
                payload.model if payload.model else None
            )
            
            return DocumentExtractResponse(
                markdown=markdown,
                page_count=1,
                has_images=False
            )
        
        else:
            raise HTTPException(
                status_code=400,
                detail=f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ ìœ í˜•ì…ë‹ˆë‹¤: {payload.file_type}"
            )
    
    except ImportError as e:
        logger.error(f"Missing dependency: {e}")
        raise HTTPException(
            status_code=500,
            detail=str(e)
        )
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Document extraction failed: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"ë¬¸ì„œ ì¶”ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# URL â†’ ë§ˆí¬ë‹¤ìš´ ì¶”ì¶œ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@router.post("/extract-url", response_model=URLExtractResponse)
async def extract_url(payload: URLExtractPayload):
    """
    URLì—ì„œ í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ë¥¼ ì¶”ì¶œí•˜ì—¬ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    
    - trafilaturaë¡œ ë³¸ë¬¸ í…ìŠ¤íŠ¸ + ì´ë¯¸ì§€ URL ì¶”ì¶œ
    - raw_text_only=Falseë©´ LLMìœ¼ë¡œ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ ì •ë¦¬
    """
    from .. import web_extractor

    url = payload.url.strip()
    if not url:
        raise HTTPException(status_code=400, detail="URLì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")

    # URL ì•ì— ìŠ¤í‚´ì´ ì—†ìœ¼ë©´ https:// ì¶”ê°€
    if not url.startswith(("http://", "https://")):
        url = "https://" + url

    try:
        # 1) HTML ê°€ì ¸ì˜¤ê¸°
        html = await web_extractor.fetch_url(url)

        # 2) ì½˜í…ì¸  ì¶”ì¶œ
        content = web_extractor.extract_content(html, url)
        title = content["title"]
        text = content["text"]
        images = content["images"]

        if not text:
            raise HTTPException(
                status_code=400,
                detail="í•´ë‹¹ URLì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            )

        # 3) ë§ˆí¬ë‹¤ìš´ ìƒì„±
        if payload.raw_text_only:
            # AI ì—†ì´ ê¸°ë³¸ ì¡°í•©
            markdown_result = web_extractor.build_markdown(
                title, text, images, url
            )
        else:
            # LLMìœ¼ë¡œ ë§ˆí¬ë‹¤ìš´ ì •ë¦¬
            raw_markdown = web_extractor.build_markdown(
                title, text, images, url
            )
            markdown_result = format_text_as_markdown(
                raw_markdown,
                payload.provider,
                payload.api_key,
                payload.language,
                payload.model if payload.model else None,
            )
            # ì¶œì²˜ ì •ë³´ê°€ LLM ì¶œë ¥ì—ì„œ ë¹ ì¡Œì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì¶”ê°€
            if url not in markdown_result:
                markdown_result = (
                    f"> ğŸ“ ì¶œì²˜: [{url}]({url})\n\n"
                    + markdown_result
                )

        logger.info("URL extracted: %s (title=%s, images=%d)", url, title, len(images))
        return URLExtractResponse(
            markdown=markdown_result,
            title=title,
            images=images,
            source_url=url,
        )

    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except HTTPException:
        raise
    except Exception as e:
        logger.error("URL extract failed: %s", e)
        raise HTTPException(
            status_code=500,
            detail=f"URL ì¶”ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# OCR ì—”ì§„ ê´€ë¦¬
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@router.get("/ocr/engines")
async def get_ocr_engines():
    """ì‚¬ìš© ê°€ëŠ¥í•œ OCR ì—”ì§„ ëª©ë¡ ë°˜í™˜"""
    from .. import ocr_client
    
    return ocr_client.get_available_engines()


@router.get("/ocr/status")
async def get_ocr_status(engine: str = "rapidocr"):
    """OCR ì—”ì§„ ìƒíƒœ í™•ì¸"""
    from .. import ocr_client
    
    info = ocr_client.get_model_info(cast(Literal["gemini", "rapidocr"], engine))
    
    return {
        "installed": info["installed"],
        "model_downloaded": info["model_downloaded"],
        "model_path": info["model_path"],
        "languages": info["languages"],
        "engine": info["engine"],
        "engine_name": info["engine_name"],
        "engine_description": info["engine_description"],
        "requires_api_key": info.get("requires_api_key", False),
    }

