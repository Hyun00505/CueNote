{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c197a5d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.57.3-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: filelock in /home/bunhine0452/miniconda3/envs/CueNote/lib/python3.11/site-packages (from transformers) (3.20.0)\n",
      "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting numpy>=1.17 (from transformers)\n",
      "  Downloading numpy-2.4.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/bunhine0452/miniconda3/envs/CueNote/lib/python3.11/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/bunhine0452/miniconda3/envs/CueNote/lib/python3.11/site-packages (from transformers) (6.0.3)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2025.11.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
      "Collecting requests (from transformers)\n",
      "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n",
      "  Downloading tokenizers-0.22.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/bunhine0452/miniconda3/envs/CueNote/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/bunhine0452/miniconda3/envs/CueNote/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<1.0,>=0.34.0->transformers)\n",
      "  Downloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests->transformers)\n",
      "  Downloading charset_normalizer-3.4.4-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (37 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->transformers)\n",
      "  Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->transformers)\n",
      "  Downloading urllib3-2.6.2-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->transformers)\n",
      "  Downloading certifi-2026.1.4-py3-none-any.whl.metadata (2.5 kB)\n",
      "Downloading transformers-4.57.3-py3-none-any.whl (12.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.22.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.4.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2025.11.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (800 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.4/800.4 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (507 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.4-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (151 kB)\n",
      "Downloading idna-3.11-py3-none-any.whl (71 kB)\n",
      "Downloading urllib3-2.6.2-py3-none-any.whl (131 kB)\n",
      "Downloading certifi-2026.1.4-py3-none-any.whl (152 kB)\n",
      "Installing collected packages: urllib3, tqdm, safetensors, regex, numpy, idna, hf-xet, charset_normalizer, certifi, requests, huggingface-hub, tokenizers, transformers\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13/13\u001b[0m [transformers][0m [transformers]ub]\n",
      "\u001b[1A\u001b[2KSuccessfully installed certifi-2026.1.4 charset_normalizer-3.4.4 hf-xet-1.2.0 huggingface-hub-0.36.0 idna-3.11 numpy-2.4.0 regex-2025.11.3 requests-2.32.5 safetensors-0.7.0 tokenizers-0.22.2 tqdm-4.67.1 transformers-4.57.3 urllib3-2.6.2\n"
     ]
    }
   ],
   "source": [
    "conda run -n CueNote pip uninstall -y torch\n",
    "conda run -n CueNote pip install torch --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc01d59f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 2.5.1+cu121\n",
      "cuda available: True\n",
      "cuda device: NVIDIA GeForce RTX 4050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"torch:\", torch.__version__)\n",
    "print(\"cuda available:\", torch.cuda.is_available())\n",
    "print(\"cuda device:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96e8e4ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.49.0-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: accelerate in /home/bunhine0452/miniconda3/envs/CueNote/lib/python3.11/site-packages (1.12.0)\n",
      "Requirement already satisfied: torch<3,>=2.3 in /home/bunhine0452/miniconda3/envs/CueNote/lib/python3.11/site-packages (from bitsandbytes) (2.5.1+cu121)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/bunhine0452/miniconda3/envs/CueNote/lib/python3.11/site-packages (from bitsandbytes) (2.4.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/bunhine0452/miniconda3/envs/CueNote/lib/python3.11/site-packages (from bitsandbytes) (25.0)\n",
      "Requirement already satisfied: filelock in /home/bunhine0452/miniconda3/envs/CueNote/lib/python3.11/site-packages (from torch<3,>=2.3->bitsandbytes) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/bunhine0452/miniconda3/envs/CueNote/lib/python3.11/site-packages (from torch<3,>=2.3->bitsandbytes) (4.15.0)\n",
      "Requirement already satisfied: networkx in /home/bunhine0452/miniconda3/envs/CueNote/lib/python3.11/site-packages (from torch<3,>=2.3->bitsandbytes) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /home/bunhine0452/miniconda3/envs/CueNote/lib/python3.11/site-packages (from torch<3,>=2.3->bitsandbytes) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/bunhine0452/miniconda3/envs/CueNote/lib/python3.11/site-packages (from torch<3,>=2.3->bitsandbytes) (2025.12.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/bunhine0452/miniconda3/envs/CueNote/lib/python3.11/site-packages (from torch<3,>=2.3->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/bunhine0452/miniconda3/envs/CueNote/lib/python3.11/site-packages (from torch<3,>=2.3->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/bunhine0452/miniconda3/envs/CueNote/lib/python3.11/site-packages (from torch<3,>=2.3->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/bunhine0452/miniconda3/envs/CueNote/lib/python3.11/site-packages (from torch<3,>=2.3->bitsandbytes) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/bunhine0452/miniconda3/envs/CueNote/lib/python3.11/site-packages (from torch<3,>=2.3->bitsandbytes) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/bunhine0452/miniconda3/envs/CueNote/lib/python3.11/site-packages (from torch<3,>=2.3->bitsandbytes) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/bunhine0452/miniconda3/envs/CueNote/lib/python3.11/site-packages (from torch<3,>=2.3->bitsandbytes) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/bunhine0452/miniconda3/envs/CueNote/lib/python3.11/site-packages (from torch<3,>=2.3->bitsandbytes) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/bunhine0452/miniconda3/envs/CueNote/lib/python3.11/site-packages (from torch<3,>=2.3->bitsandbytes) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/bunhine0452/miniconda3/envs/CueNote/lib/python3.11/site-packages (from torch<3,>=2.3->bitsandbytes) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/bunhine0452/miniconda3/envs/CueNote/lib/python3.11/site-packages (from torch<3,>=2.3->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: triton==3.1.0 in /home/bunhine0452/miniconda3/envs/CueNote/lib/python3.11/site-packages (from torch<3,>=2.3->bitsandbytes) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/bunhine0452/miniconda3/envs/CueNote/lib/python3.11/site-packages (from torch<3,>=2.3->bitsandbytes) (1.13.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/bunhine0452/miniconda3/envs/CueNote/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<3,>=2.3->bitsandbytes) (12.9.86)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/bunhine0452/miniconda3/envs/CueNote/lib/python3.11/site-packages (from sympy==1.13.1->torch<3,>=2.3->bitsandbytes) (1.3.0)\n",
      "Requirement already satisfied: psutil in /home/bunhine0452/miniconda3/envs/CueNote/lib/python3.11/site-packages (from accelerate) (7.2.1)\n",
      "Requirement already satisfied: pyyaml in /home/bunhine0452/miniconda3/envs/CueNote/lib/python3.11/site-packages (from accelerate) (6.0.3)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /home/bunhine0452/miniconda3/envs/CueNote/lib/python3.11/site-packages (from accelerate) (0.36.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/bunhine0452/miniconda3/envs/CueNote/lib/python3.11/site-packages (from accelerate) (0.7.0)\n",
      "Requirement already satisfied: requests in /home/bunhine0452/miniconda3/envs/CueNote/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/bunhine0452/miniconda3/envs/CueNote/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/bunhine0452/miniconda3/envs/CueNote/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate) (1.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/bunhine0452/miniconda3/envs/CueNote/lib/python3.11/site-packages (from jinja2->torch<3,>=2.3->bitsandbytes) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/bunhine0452/miniconda3/envs/CueNote/lib/python3.11/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/bunhine0452/miniconda3/envs/CueNote/lib/python3.11/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/bunhine0452/miniconda3/envs/CueNote/lib/python3.11/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.6.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/bunhine0452/miniconda3/envs/CueNote/lib/python3.11/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2026.1.4)\n",
      "Downloading bitsandbytes-0.49.0-py3-none-manylinux_2_24_x86_64.whl (59.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m  \u001b[33m0:00:05\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: bitsandbytes\n",
      "Successfully installed bitsandbytes-0.49.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U bitsandbytes accelerate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26a0f75d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No '{' found in model output.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 124\u001b[39m, in \u001b[36mcall_json\u001b[39m\u001b[34m(document, task)\u001b[39m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparse_json_from_llm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    126\u001b[39m     \u001b[38;5;66;03m# 1회 재시도: \"JSON만\" 수정하도록 강제\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 55\u001b[39m, in \u001b[36mparse_json_from_llm\u001b[39m\u001b[34m(text)\u001b[39m\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mparse_json_from_llm\u001b[39m(text: \u001b[38;5;28mstr\u001b[39m) -> Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m     json_str = \u001b[43mextract_first_json_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     56\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m json.loads(json_str)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 25\u001b[39m, in \u001b[36mextract_first_json_object\u001b[39m\u001b[34m(text)\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m start == -\u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNo \u001b[39m\u001b[33m'\u001b[39m\u001b[33m{\u001b[39m\u001b[33m'\u001b[39m\u001b[33m found in model output.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     27\u001b[39m depth = \u001b[32m0\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m: No '{' found in model output.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 170\u001b[39m\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    147\u001b[39m     doc = \u001b[33m\"\"\"\u001b[39m\u001b[33m현대자동차·기아의 자동차 부품을 운송하는 화물노동자 김아무개씨는 2024년 8월과 10월 배송 착오를 했다. 이로 인해 214분간 공장 생산라인이 중단됐다. 현대모비스 자회사인 부품업체 모트라스는 2억9천만원의 손해가 발생했다며 김씨와 위수탁계약을 맺은 운송 협력업체에 항의했다.\u001b[39m\n\u001b[32m    148\u001b[39m \n\u001b[32m    149\u001b[39m \u001b[33m김씨는 모든 손해를 부담해야 했다. 운송업체는 김씨에게 책임을 돌리며, 지난해 6월 손해금을 김씨가 배상한다는 내용의 ‘라인중단 클레임 변제 합의서’를 김씨와 체결했기 때문이다. 김씨는 지입차를 팔아 1억원가량을 갚고, 모트라스·유니투스와 계약한 물류사의 직영기사로 고용돼 임금 중 일부를 떼어내 갚기로 합의했다. 지입차주에서 직영기사로 일하게 되며 한 달 보수가 절반으로 줄어드는 바람에 나머지 변제금은 보류 중이다.\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    168\u001b[39m \n\u001b[32m    169\u001b[39m \u001b[33m출처 : 매일노동뉴스(https://www.labortoday.co.kr)\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m     result = \u001b[43mcall_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    171\u001b[39m     \u001b[38;5;28mprint\u001b[39m(json.dumps(result, ensure_ascii=\u001b[38;5;28;01mFalse\u001b[39;00m, indent=\u001b[32m2\u001b[39m))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 143\u001b[39m, in \u001b[36mcall_json\u001b[39m\u001b[34m(document, task)\u001b[39m\n\u001b[32m    127\u001b[39m         repair_prompt = \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[33mYour previous output was not valid JSON or contained extra text.\u001b[39m\n\u001b[32m    129\u001b[39m \u001b[33mReturn ONLY ONE valid JSON object that matches the schema.\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    139\u001b[39m \u001b[38;5;132;01m{\u001b[39;00mdocument\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[32m    140\u001b[39m \u001b[33m\"\"\"\u001b[39m.strip()\n\u001b[32m    142\u001b[39m         text2 = generate_text(repair_prompt, max_new_tokens=\u001b[32m256\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m143\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparse_json_from_llm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext2\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 55\u001b[39m, in \u001b[36mparse_json_from_llm\u001b[39m\u001b[34m(text)\u001b[39m\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mparse_json_from_llm\u001b[39m(text: \u001b[38;5;28mstr\u001b[39m) -> Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m     json_str = \u001b[43mextract_first_json_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     56\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m json.loads(json_str)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 25\u001b[39m, in \u001b[36mextract_first_json_object\u001b[39m\u001b[34m(text)\u001b[39m\n\u001b[32m     23\u001b[39m start = text.find(\u001b[33m\"\u001b[39m\u001b[33m{\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m start == -\u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNo \u001b[39m\u001b[33m'\u001b[39m\u001b[33m{\u001b[39m\u001b[33m'\u001b[39m\u001b[33m found in model output.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     27\u001b[39m depth = \u001b[32m0\u001b[39m\n\u001b[32m     28\u001b[39m in_str = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: No '{' found in model output."
     ]
    }
   ],
   "source": [
    "import json\n",
    "from typing import Any, Dict, Optional\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "#MODEL_DIR = \"./data/Phi-3.5-mini-instruct\"   # 또는 \"./data/SmolLM2-1.7B-Instruct\"\n",
    "MODEL_DIR = \"./data/SmolLM2-1.7B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR, use_fast=True)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_DIR,\n",
    "    device_map=\"cuda\",          # ✅ 아예 GPU 고정 (offload 방지)\n",
    "    load_in_4bit=True,          # ✅ 4bit 양자화\n",
    "    torch_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "def extract_first_json_object(text: str) -> str:\n",
    "    \"\"\"\n",
    "    LLM 출력에서 '첫 번째' JSON 객체({ ... })만 중괄호 균형 기준으로 추출.\n",
    "    JSON 앞/뒤에 다른 텍스트가 있어도 안전.\n",
    "    \"\"\"\n",
    "    start = text.find(\"{\")\n",
    "    if start == -1:\n",
    "        raise ValueError(\"No '{' found in model output.\")\n",
    "\n",
    "    depth = 0\n",
    "    in_str = False\n",
    "    escape = False\n",
    "\n",
    "    for i in range(start, len(text)):\n",
    "        ch = text[i]\n",
    "\n",
    "        if in_str:\n",
    "            if escape:\n",
    "                escape = False\n",
    "            elif ch == \"\\\\\":\n",
    "                escape = True\n",
    "            elif ch == '\"':\n",
    "                in_str = False\n",
    "            continue\n",
    "\n",
    "        if ch == '\"':\n",
    "            in_str = True\n",
    "        elif ch == \"{\":\n",
    "            depth += 1\n",
    "        elif ch == \"}\":\n",
    "            depth -= 1\n",
    "            if depth == 0:\n",
    "                return text[start:i + 1]\n",
    "\n",
    "    raise ValueError(\"Unbalanced braces; could not extract JSON object.\")\n",
    "\n",
    "def parse_json_from_llm(text: str) -> Dict[str, Any]:\n",
    "    json_str = extract_first_json_object(text)\n",
    "    return json.loads(json_str)\n",
    "\n",
    "def build_prompt(document: str, task: str) -> str:\n",
    "    schema = {\n",
    "        \"task\": task,\n",
    "        \"language\": \"ko\",\n",
    "        \"output_schema\": {\n",
    "            \"category\": \"one of [finance, legal, tech, medical, general, other]\",\n",
    "            \"summary\": \"string (<= 120 chars)\",\n",
    "            \"keywords\": \"array of strings (3~8 items)\",\n",
    "            \"confidence\": \"number (0.0~1.0)\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are an on-device document understanding model.\n",
    "\n",
    "STRICT RULES:\n",
    "- Output MUST be valid JSON object.\n",
    "- Output MUST contain ONLY the JSON object (no markdown, no extra text).\n",
    "- Output MUST match the required schema keys exactly: category, summary, keywords, confidence.\n",
    "- keywords MUST be a JSON array of 3~8 strings.\n",
    "- confidence MUST be a number between 0.0 and 1.0.\n",
    "- If uncertain, still output JSON with best guess and lower confidence.\n",
    "\n",
    "REQUIRED JSON FORMAT EXAMPLE:\n",
    "{{\n",
    "  \"category\": \"tech\",\n",
    "  \"summary\": \"요약문...\",\n",
    "  \"keywords\": [\"키워드1\", \"키워드2\", \"키워드3\"],\n",
    "  \"confidence\": 0.72\n",
    "}}\n",
    "\n",
    "TASK SPEC:\n",
    "{json.dumps(schema, ensure_ascii=False)}\n",
    "\n",
    "DOCUMENT:\n",
    "{document}\n",
    "\"\"\".strip()\n",
    "\n",
    "    return prompt\n",
    "\n",
    "def generate_text(prompt: str, max_new_tokens: int = 256) -> str:\n",
    "    \"\"\"\n",
    "    중요: 모델 출력에서 '생성된 토큰만' 디코딩해서 프롬프트가 섞이지 않게 한다.\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=False,\n",
    "            temperature=0.7,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "\n",
    "    # ✅ 프롬프트 길이만큼 잘라서 \"새로 생성된 부분만\" 디코딩\n",
    "    gen_ids = out[0][inputs[\"input_ids\"].shape[1]:]\n",
    "    text = tokenizer.decode(gen_ids, skip_special_tokens=True).strip()\n",
    "    return text\n",
    "\n",
    "def call_json(document: str, task: str = \"classify_and_summarize\") -> Dict[str, Any]:\n",
    "    prompt = build_prompt(document, task)\n",
    "    text = generate_text(prompt)\n",
    "\n",
    "    try:\n",
    "        return parse_json_from_llm(text)\n",
    "    except Exception:\n",
    "        # 1회 재시도: \"JSON만\" 수정하도록 강제\n",
    "        repair_prompt = f\"\"\"\n",
    "Your previous output was not valid JSON or contained extra text.\n",
    "Return ONLY ONE valid JSON object that matches the schema.\n",
    "No markdown. No explanations. No extra characters.\n",
    "\n",
    "SCHEMA (keys must be exactly these):\n",
    "- category: one of [finance, legal, tech, medical, general, other]\n",
    "- summary: string (<= 120 chars)\n",
    "- keywords: array of 3~8 strings\n",
    "- confidence: number (0.0~1.0)\n",
    "\n",
    "DOCUMENT:\n",
    "{document}\n",
    "\"\"\".strip()\n",
    "\n",
    "        text2 = generate_text(repair_prompt, max_new_tokens=256)\n",
    "        return parse_json_from_llm(text2)\n",
    "\n",
    "# ---- 테스트\n",
    "if __name__ == \"__main__\":\n",
    "    doc = \"\"\"현대자동차·기아의 자동차 부품을 운송하는 화물노동자 김아무개씨는 2024년 8월과 10월 배송 착오를 했다. 이로 인해 214분간 공장 생산라인이 중단됐다. 현대모비스 자회사인 부품업체 모트라스는 2억9천만원의 손해가 발생했다며 김씨와 위수탁계약을 맺은 운송 협력업체에 항의했다.\n",
    "\n",
    "김씨는 모든 손해를 부담해야 했다. 운송업체는 김씨에게 책임을 돌리며, 지난해 6월 손해금을 김씨가 배상한다는 내용의 ‘라인중단 클레임 변제 합의서’를 김씨와 체결했기 때문이다. 김씨는 지입차를 팔아 1억원가량을 갚고, 모트라스·유니투스와 계약한 물류사의 직영기사로 고용돼 임금 중 일부를 떼어내 갚기로 합의했다. 지입차주에서 직영기사로 일하게 되며 한 달 보수가 절반으로 줄어드는 바람에 나머지 변제금은 보류 중이다.\n",
    "\n",
    "특수고용 노동자라는 이유로 ‘무한책임’\n",
    "\n",
    "이 같은 일은 단지 김씨만 겪고 있는 것이 아니다. 기아·현대자동차 화물운송 노동자 여러명이 비슷한 상태에 있다. 안현성 전국연대통합건설산업노조 화물운송분과 현대기아자동차 부품운송지부장은 6일 <매일노동뉴스>에 “전국 각지에 분당 손해비용을 계산해 몇백만 원, 몇천만 원, 1억원짜리 무한책임 변제를 강요하는 일들이 일어나고 있다”고 말했다.\n",
    "\n",
    "화물노동자들에게 이 같은 책임이 지워지는 이유는 고용형태 때문이다. 이들은 계약상 특수고용노동자 신분이기 때문에 개인사업자로 분류된다. 이 때문에 부품운송이 지연돼 공장 생산라인이 지연되거나 중단되는 경우, 분당 거액의 비용이 ‘생산공정 중단 책임비용’이라는 이름으로 노동자들에게 부과된다. 노조에 따르면 현대자동차 아산공장 기준 책임비용은 1분당 152만8천원이다.\n",
    "\n",
    "화물노동자들은 유한책임 제도로 바꿔야 한다고 요구하고 있다. 단순 실수 등으로 화물노동자의 삶이 ‘송두리째 뒤집어지는’ 일은 막아야 한다는 것이다. 이들은 현대차·기아, 현대모비스, 모트라스 소속 생산직 노동자들의 과실로 생산공정이 가동되지 않는 경우, 징계를 받을 수 있지만 분당 손해비용을 개인에게 부과하는 일이 없다는 사실을 강조했다.\n",
    "\n",
    "“원청 교섭 나서지 않으면 9일 파업”\n",
    "\n",
    "이들은 현대자동차·기아, 현대글로비스·현대모비스·모트라스·유니투스 등 원청사가 화물노동자와의 교섭에 나서라고 요구했다. 생산공정 중단 책임비용 청구는 현대자동차·기아에서부터 현대모비스·모트라스(유니투스)·현대글로비스·물류사를 거쳐 노동자에게 전가되는 구조기에, 이들 기업이 나서지 않으면 해결이 안 된다는 이유다.\n",
    "\n",
    "개정 노동조합 및 노동관계조정법(노조법)에 따라 하청노동자가 원청사용자가 교섭할 수 있게 된 만큼, 실제로 원청과의 교섭이 이뤄질 가능성도 없지 않다. 지부는 부품을 싣고 내리는 특수 설비가 차량에 탑재돼 있고, 자동화 시스템을 통해 공장에 부품을 내리는 만큼 ‘하나의 사업’에서 일어나는 마지막 공정이라고 보고 있다.\n",
    "\n",
    "지부에 법률자문을 하는 진우람 공인노무사(노동법률 신임)는 “배차 조정 등 업무지시나 운송료 결정 등에 있어 원청이 실질적 지배력이 있다는 정황증거가 존재하는 만큼 교섭 사용자로 인정될 수 있다고 본다”며 “물류업체와 교섭할 때 모트라스 등 원청 직원이 배석을 하고 있다. 자신들이 조건을 결정하는 지위에 있다는 것을 인지하고 있는 것”이라고 설명했다.\n",
    "\n",
    "지부는 원청이 대화 의지를 밟히지 않으면 파업을 하겠다는 입장이다. 지부는 이날 오후 국회 소통관에서 기자회견을 열고 “원청과 계열사가 문제 해결에 나서지 못할 경우, 모트라스 직서열 차량과 글로비스 LST센터 소속 차량 등 200여대 규모의 연대 행동에 나설 수밖에 없다”며 “9일 쟁의행위를 실시하겠다”고 했다. 현대글로비스의 물류운송협력업체와 화물노동자들의 교섭은 지난달 31일 전남지방노동위원회에서 조정중지됐다. 모트라스의 물류운송협력업체와 화물노동자들의 교섭은 이달 2일 중앙노동위원회에서 조정중지됐다.\n",
    "\"\"\"\n",
    "    result = call_json(doc)\n",
    "    print(json.dumps(result, ensure_ascii=False, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51a62097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"category\": \"tech\",\n",
      "  \"summary\": \"삼성전자가 차세대 반도체 공정 로드맵을 발표하고 2나노 공정 확대 계획을 밝혔다.\",\n",
      "  \"keywords\": [\n",
      "    \"삼성전자\",\n",
      "    \"반도체 공정\",\n",
      "    \"2나노 공정\",\n",
      "    \"로드맵\"\n",
      "  ],\n",
      "  \"confidence\": 0.95\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    doc = \"삼성전자는 차세대 반도체 공정 로드맵을 발표했으며, 2나노 공정 확대 계획을 밝혔다...\"\n",
    "    result = call_json(doc)\n",
    "    print(json.dumps(result, ensure_ascii=False, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CueNote",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
